{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oHFCsV0z-Jw"
      },
      "source": [
        "# Finetune Llama-3 with LLaMA Factory\n",
        "\n",
        "Please use a **free** Tesla T4 Colab GPU to run this!\n",
        "\n",
        "Project homepage: https://github.com/hiyouga/LLaMA-Factory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr7rB3szzhtx"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giM74oK1rRIH",
        "outputId": "99ae40a4-4905-44c2-e511-d41dce153670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: 目标路径 'LLaMA-Factory' 已经存在，并且不是一个空目录。\n"
          ]
        }
      ],
      "source": [
        "# %cd /content/\n",
        "# %rm -rf LLaMA-Factory\n",
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/anonymous/桌面/NursingLLM/LLaMA-Factory\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/             \u001b[01;34mevaluation\u001b[0m/   pyproject.toml    setup.py\n",
            "\u001b[01;34mcache\u001b[0m/              \u001b[01;34mexamples\u001b[0m/     README.md         \u001b[01;34msrc\u001b[0m/\n",
            "CITATION.cff        LICENSE       README_zh.md      \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/               \u001b[01;34mllama3_lora\u001b[0m/  requirements.txt  train_llama3.json\n",
            "docker-compose.yml  Makefile      \u001b[01;34msaves\u001b[0m/\n",
            "Dockerfile          MANIFEST.in   \u001b[01;34mscripts\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd LLaMA-Factory\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Obtaining file:///home/anonymous/%E6%A1%8C%E9%9D%A2/NursingLLM/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.41.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (4.41.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.20.0)\n",
            "Requirement already satisfied: accelerate>=0.30.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.31.0)\n",
            "Requirement already satisfied: peft>=0.11.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.11.1)\n",
            "Requirement already satisfied: trl>=0.8.6 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.9.4)\n",
            "Requirement already satisfied: gradio>=4.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (4.36.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (1.13.1)\n",
            "Requirement already satisfied: einops in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.7.0)\n",
            "Requirement already satisfied: protobuf in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (5.27.1)\n",
            "Requirement already satisfied: uvicorn in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.30.1)\n",
            "Requirement already satisfied: pydantic in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.7.4)\n",
            "Requirement already satisfied: fastapi in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.111.0)\n",
            "Requirement already satisfied: sse-starlette in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.1.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (3.9.0)\n",
            "Requirement already satisfied: fire in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.6.0)\n",
            "Requirement already satisfied: packaging in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (6.0.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (1.26.4)\n",
            "Requirement already satisfied: bitsandbytes>=0.39.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.43.1)\n",
            "Requirement already satisfied: torch>=1.13.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.3.1)\n",
            "Requirement already satisfied: psutil in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (5.9.0)\n",
            "Requirement already satisfied: huggingface-hub in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.4.3)\n",
            "Requirement already satisfied: filelock in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.15.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->llamafactory==0.8.3.dev0) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.9.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (5.3.0)\n",
            "Requirement already satisfied: ffmpy in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.10.5)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (10.3.0)\n",
            "Requirement already satisfied: pydub in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.4.10)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.2.2)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from gradio-client==1.0.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (11.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from pydantic->llamafactory==0.8.3.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from pydantic->llamafactory==0.8.3.dev0) (2.18.4)\n",
            "Requirement already satisfied: sympy in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (1.12.1)\n",
            "Requirement already satisfied: networkx in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.8.3.dev0) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (0.19.1)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from trl>=0.8.6->llamafactory==0.8.3.dev0) (0.8.4)\n",
            "Requirement already satisfied: click>=7.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fastapi->llamafactory==0.8.3.dev0) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fastapi->llamafactory==0.8.3.dev0) (2.2.0)\n",
            "Requirement already satisfied: six in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fire->llamafactory==0.8.3.dev0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from fire->llamafactory==0.8.3.dev0) (2.4.0)\n",
            "Requirement already satisfied: anyio in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from sse-starlette->llamafactory==0.8.3.dev0) (4.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.22.0)\n",
            "Requirement already satisfied: toolz in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (3.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.3.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from anyio->sse-starlette->llamafactory==0.8.3.dev0) (1.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (13.7.1)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (1.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.22.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from sympy->torch>=1.13.1->llamafactory==0.8.3.dev0) (1.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.1.2)\n",
            "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.8.3.dev0-0.editable-py3-none-any.whl size=18879 sha256=b7a4b02efc0c536dc92adaf181102558fb9fd068748efa135cf64fc49ae11217\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u1crmi19/wheels/e9/6b/fa/f360eef24614aacaf8dd8b4caafdd37ba9978ef16df86d83ec\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: llamafactory\n",
            "  Attempting uninstall: llamafactory\n",
            "    Found existing installation: llamafactory 0.8.3.dev0\n",
            "    Uninstalling llamafactory-0.8.3.dev0:\n",
            "      Successfully uninstalled llamafactory-0.8.3.dev0\n",
            "Successfully installed llamafactory-0.8.3.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install -e .[torch,bitsandbytes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RXn_YQnn9f"
      },
      "source": [
        "### Check GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZkN-ktlsnrdU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "try:\n",
        "  assert torch.cuda.is_available() is True\n",
        "except AssertionError:\n",
        "  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeYs5Lz-QJYk"
      },
      "source": [
        "## Update Identity Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ap_fvMBsQHJc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/LLaMA-Factory/'\n",
            "/home/anonymous/桌面/NursingLLM/LLaMA-Factory\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "\n",
        "NAME = \"Llama-3\"\n",
        "AUTHOR = \"LLaMA Factory\"\n",
        "\n",
        "with open(\"data/identity.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "  dataset = json.load(f)\n",
        "\n",
        "for sample in dataset:\n",
        "  sample[\"output\"] = sample[\"output\"].replace(\"{{\"+ \"name\" + \"}}\", NAME).replace(\"{{\"+ \"author\" + \"}}\", AUTHOR)\n",
        "\n",
        "with open(\"data/identity.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(dataset, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QiXcvdzzW3Y"
      },
      "source": [
        "## Fine-tune model via LLaMA Board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YLsdS6V5yUMy"
      },
      "outputs": [],
      "source": [
        "# %cd /content/LLaMA-Factory/\n",
        "# !GRADIO_SHARE=1 llamafactory-cli webui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgR3UFhB0Ifq"
      },
      "source": [
        "## Fine-tune model via Command Line\n",
        "\n",
        "It takes ~30min for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CS0Qk5OR0i4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/24/2024 12:34:37 - INFO - llamafactory.cli - Initializing distributed tasks at: 127.0.0.1:23005\n",
            "W0624 12:34:38.024000 135273406801408 torch/distributed/run.py:757] \n",
            "W0624 12:34:38.024000 135273406801408 torch/distributed/run.py:757] *****************************************\n",
            "W0624 12:34:38.024000 135273406801408 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W0624 12:34:38.024000 135273406801408 torch/distributed/run.py:757] *****************************************\n",
            "06/24/2024 12:34:40 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
            "06/24/2024 12:34:40 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
            "06/24/2024 12:34:40 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
            "06/24/2024 12:34:40 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
            "06/24/2024 12:34:40 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
            "06/24/2024 12:34:40 - INFO - llamafactory.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 12:34:41,451 >> loading file tokenizer.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 12:34:41,451 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 12:34:41,451 >> loading file special_tokens_map.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 12:34:41,451 >> loading file tokenizer_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
            "[WARNING|logging.py:314] 2024-06-24 12:34:41,623 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "06/24/2024 12:34:41 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
            "06/24/2024 12:34:41 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "06/24/2024 12:34:41 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
            "Generating train split: 91 examples [00:00, 21611.55 examples/s]\n",
            "Converting format of dataset: 100%|███| 91/91 [00:00<00:00, 32940.51 examples/s]\n",
            "06/24/2024 12:34:42 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n",
            "06/24/2024 12:34:43 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n",
            "Running tokenizer on dataset: 100%|██| 591/591 [00:00<00:00, 4382.86 examples/s]\n",
            "input_ids:\n",
            "[128000, 128006, 882, 128007, 271, 6151, 128009, 128006, 78191, 128007, 271, 9906, 0, 358, 1097, 445, 81101, 12, 18, 11, 459, 15592, 18328, 8040, 555, 445, 8921, 4940, 17367, 13, 2650, 649, 358, 7945, 499, 3432, 30, 128009]\n",
            "inputs:\n",
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Hello! I am Llama-3, an AI assistant developed by LLaMA Factory. How can I assist you today?<|eot_id|>\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 9906, 0, 358, 1097, 445, 81101, 12, 18, 11, 459, 15592, 18328, 8040, 555, 445, 8921, 4940, 17367, 13, 2650, 649, 358, 7945, 499, 3432, 30, 128009]\n",
            "labels:\n",
            "Hello! I am Llama-3, an AI assistant developed by LLaMA Factory. How can I assist you today?<|eot_id|>\n",
            "06/24/2024 12:34:44 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n",
            "/home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "[INFO|configuration_utils.py:733] 2024-06-24 12:34:45,739 >> loading configuration file config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
            "[INFO|configuration_utils.py:796] 2024-06-24 12:34:45,740 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "06/24/2024 12:34:45 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
            "[WARNING|quantization_config.py:393] 2024-06-24 12:34:45,754 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "[INFO|modeling_utils.py:3474] 2024-06-24 12:34:45,755 >> loading weights file model.safetensors from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
            "[INFO|modeling_utils.py:1519] 2024-06-24 12:34:45,768 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 12:34:45,770 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009\n",
            "}\n",
            "\n",
            "06/24/2024 12:34:45 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "[INFO|modeling_utils.py:4280] 2024-06-24 12:34:48,065 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4288] 2024-06-24 12:34:48,065 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:917] 2024-06-24 12:34:48,299 >> loading configuration file generation_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 12:34:48,300 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128009\n",
            "  ]\n",
            "}\n",
            "\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.model_utils.misc - Found linear modules: q_proj,up_proj,down_proj,k_proj,o_proj,v_proj,gate_proj\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
            "[INFO|trainer.py:641] 2024-06-24 12:34:48,535 >> Using auto half precision backend\n",
            "06/24/2024 12:34:48 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.\n",
            "06/24/2024 12:34:48 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.model_utils.misc - Found linear modules: q_proj,v_proj,k_proj,down_proj,gate_proj,o_proj,up_proj\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
            "06/24/2024 12:34:49 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
            "[INFO|trainer.py:2078] 2024-06-24 12:34:49,897 >> ***** Running training *****\n",
            "[INFO|trainer.py:2079] 2024-06-24 12:34:49,897 >>   Num examples = 591\n",
            "[INFO|trainer.py:2080] 2024-06-24 12:34:49,897 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2081] 2024-06-24 12:34:49,897 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:2084] 2024-06-24 12:34:49,897 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2085] 2024-06-24 12:34:49,897 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2086] 2024-06-24 12:34:49,897 >>   Total optimization steps = 111\n",
            "[INFO|trainer.py:2087] 2024-06-24 12:34:49,900 >>   Number of trainable parameters = 20,971,520\n",
            "{'loss': 1.3552, 'grad_norm': 0.8063373565673828, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.27}\n",
            "{'loss': 1.1085, 'grad_norm': 0.6462079286575317, 'learning_rate': 4.919871753490891e-05, 'epoch': 0.54}\n",
            "{'loss': 1.0229, 'grad_norm': 0.7174493670463562, 'learning_rate': 4.6031338320779534e-05, 'epoch': 0.81}\n",
            "{'loss': 0.9907, 'grad_norm': 1.8040940761566162, 'learning_rate': 4.0763816677113064e-05, 'epoch': 1.08}\n",
            "{'loss': 0.8364, 'grad_norm': 0.9492313861846924, 'learning_rate': 3.392215553979679e-05, 'epoch': 1.35}\n",
            "{'loss': 0.8434, 'grad_norm': 0.5723644495010376, 'learning_rate': 2.6189547895593562e-05, 'epoch': 1.62}\n",
            "{'loss': 0.7964, 'grad_norm': 0.3749225437641144, 'learning_rate': 1.8338154657749128e-05, 'epoch': 1.89}\n",
            "{'loss': 0.7051, 'grad_norm': 0.5393953919410706, 'learning_rate': 1.1151998403347244e-05, 'epoch': 2.16}\n",
            "{'loss': 0.7014, 'grad_norm': 0.5221250057220459, 'learning_rate': 5.348672631430318e-06, 'epoch': 2.43}\n",
            "{'loss': 0.6497, 'grad_norm': 0.734383225440979, 'learning_rate': 1.5076844803522922e-06, 'epoch': 2.7}\n",
            "{'loss': 0.6634, 'grad_norm': 0.681142270565033, 'learning_rate': 1.2586440420372936e-08, 'epoch': 2.97}\n",
            "100%|█████████████████████████████████████████| 111/111 [08:17<00:00,  4.55s/it][INFO|trainer.py:2329] 2024-06-24 12:43:07,256 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 497.3566, 'train_samples_per_second': 3.565, 'train_steps_per_second': 0.223, 'train_loss': 0.8756650095587378, 'epoch': 3.0}\n",
            "100%|█████████████████████████████████████████| 111/111 [08:17<00:00,  4.48s/it]\n",
            "[INFO|trainer.py:3410] 2024-06-24 12:43:07,261 >> Saving model checkpoint to llama3_lora\n",
            "[INFO|configuration_utils.py:733] 2024-06-24 12:43:07,996 >> loading configuration file config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
            "[INFO|configuration_utils.py:796] 2024-06-24 12:43:07,998 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2513] 2024-06-24 12:43:08,117 >> tokenizer config file saved in llama3_lora/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2522] 2024-06-24 12:43:08,117 >> Special tokens file saved in llama3_lora/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               = 16255807GF\n",
            "  train_loss               =     0.8757\n",
            "  train_runtime            = 0:08:17.35\n",
            "  train_samples_per_second =      3.565\n",
            "  train_steps_per_second   =      0.223\n",
            "[INFO|modelcard.py:450] 2024-06-24 12:43:08,196 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  stage=\"sft\",                        # do supervised fine-tuning\n",
        "  do_train=True,\n",
        "  model_name_or_path=\"unsloth/llama-3-8b-Instruct-bnb-4bit\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
        "  dataset=\"identity,alpaca_en_demo\",             # use alpaca and identity datasets\n",
        "  template=\"llama3\",                     # use llama3 prompt template\n",
        "  finetuning_type=\"lora\",                   # use LoRA adapters to save memory\n",
        "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
        "  output_dir=\"llama3_lora\",                  # the path to save LoRA adapters\n",
        "  overwrite_output_dir=True,                # overwrite the output directory\n",
        "  per_device_train_batch_size=2,               # the batch size\n",
        "  gradient_accumulation_steps=4,               # the gradient accumulation steps\n",
        "  lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n",
        "  logging_steps=10,                      # log every 10 steps\n",
        "  warmup_ratio=0.1,                      # use warmup scheduler\n",
        "  save_steps=1000,                      # save checkpoint every 1000 steps\n",
        "  learning_rate=5e-5,                     # the learning rate\n",
        "  num_train_epochs=3.0,                    # the epochs of training\n",
        "  max_samples=500,                      # use 500 examples in each dataset\n",
        "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
        "  quantization_bit=4,                     # use 4-bit QLoRA\n",
        "  loraplus_lr_ratio=16.0,                   # use LoRA+ algorithm with lambda=16.0\n",
        "  fp16=True,                         # use float16 mixed precision training\n",
        ")\n",
        "\n",
        "json.dump(args, open(\"train_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "# %cd /content/LLaMA-Factory/\n",
        "\n",
        "!llamafactory-cli train train_llama3.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVNaC-xS5N40"
      },
      "source": [
        "## Infer the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oh8H9A_25SF9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/LLaMA-Factory/'\n",
            "/home/anonymous/桌面/NursingLLM/LLaMA-Factory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:37:44,826 >> loading file tokenizer.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:37:44,827 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:37:44,828 >> loading file special_tokens_map.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:37:44,829 >> loading file tokenizer_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
            "[WARNING|logging.py:314] 2024-06-24 14:37:45,001 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/24/2024 14:37:45 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "[INFO|configuration_utils.py:733] 2024-06-24 14:37:45,239 >> loading configuration file config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
            "[INFO|configuration_utils.py:796] 2024-06-24 14:37:45,242 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/24/2024 14:37:45 - INFO - llamafactory.model.model_utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
            "06/24/2024 14:37:45 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING|quantization_config.py:393] 2024-06-24 14:37:45,248 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "[INFO|modeling_utils.py:3474] 2024-06-24 14:37:45,251 >> loading weights file model.safetensors from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
            "[INFO|modeling_utils.py:1519] 2024-06-24 14:37:45,272 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 14:37:45,274 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009\n",
            "}\n",
            "\n",
            "[INFO|quantizer_bnb_4bit.py:105] 2024-06-24 14:37:45,329 >> target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n",
            "[INFO|modeling_utils.py:4280] 2024-06-24 14:37:47,232 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4288] 2024-06-24 14:37:47,232 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:917] 2024-06-24 14:37:47,494 >> loading configuration file generation_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 14:37:47,495 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128009\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/24/2024 14:37:47 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "06/24/2024 14:37:47 - INFO - llamafactory.model.adapter - Loaded adapter(s): llama3_lora\n",
            "06/24/2024 14:37:47 - INFO - llamafactory.model.loader - all params: 8051232768\n",
            "Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.\n",
            "Assistant: 您好，我是 Llama-3，一个由 LLaMA Factory 开发的人工智能助手。请问有什么可以帮助您的吗？\n",
            "Assistant: 作为 LLaMA-3，我可以访问 LLaMA Factory 的数据集，包括但不限于以下几个方面的数据集：\n",
            "\n",
            "1.自然语言处理数据集：例如，20 Newsgroups，IMDB，AG News，20 Questions，Sentiment140等。\n",
            "2.计算机视觉数据集：例如，ImageNet，CIFAR-10，CIFAR-100，PASCAL VOC，Stanford Large Network Dataset等。\n",
            "3.机器学习和优化数据集：例如，LIBSVM数据集，UCI Machine Learning Repository，KEEL Dataset Collection等。\n",
            "\n",
            "这些数据集都可以用来训练和测试机器学习算法。\n",
            "Assistant: 我是由 LLaMA Factory 开发的人工智能助手。LLaMA Factory 是一个人工智能研究机构，致力于开发和应用人工智能技术。\n",
            "Assistant: 您可以通过自然语言对我进行命令和询问。我可以回答问题、提供信息、完成任务等。\n",
            "Assistant: 使用我需要按照以下步骤进行：\n",
            "\n",
            "1. 在聊天窗口中输入您的问题或命令。\n",
            "2. 点击“发送”按钮发送信息。\n",
            "3. 我会尽力回答您的问题或完成您的命令。\n",
            "\n",
            "我可以理解自然语言，所以您可以使用正常的语言与我交流。\n",
            "Assistant: 您可以访问 LLaMA Factory 的官方网站了解他们的使用方法。他们的系统可以根据用户的需求提供相应的帮助。\n",
            "Assistant: nǐ hǎo! (您好!)\n",
            "Assistant: 您好！我是 LLaMA-3，一个由 LLaMA Factory 开发的人工智能助手。请问有什么可以帮助您的吗？\n"
          ]
        }
      ],
      "source": [
        "from llamafactory.chat import ChatModel\n",
        "from llamafactory.extras.misc import torch_gc\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "\n",
        "args = dict(\n",
        "  model_name_or_path=\"unsloth/llama-3-8b-Instruct-bnb-4bit\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
        "  adapter_name_or_path=\"llama3_lora\",            # load the saved LoRA adapters\n",
        "  template=\"llama3\",                     # same to the one in training\n",
        "  finetuning_type=\"lora\",                  # same to the one in training\n",
        "  quantization_bit=4,                    # load 4-bit quantized model\n",
        ")\n",
        "chat_model = ChatModel(args)\n",
        "\n",
        "messages = []\n",
        "print(\"Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.\")\n",
        "while True:\n",
        "  query = input(\"\\nUser: \")\n",
        "  if query.strip() == \"exit\":\n",
        "    break\n",
        "  if query.strip() == \"clear\":\n",
        "    messages = []\n",
        "    torch_gc()\n",
        "    print(\"History has been removed.\")\n",
        "    continue\n",
        "\n",
        "  messages.append({\"role\": \"user\", \"content\": query})\n",
        "  print(\"Assistant: \", end=\"\", flush=True)\n",
        "\n",
        "  response = \"\"\n",
        "  for new_text in chat_model.stream_chat(messages):\n",
        "    print(new_text, end=\"\", flush=True)\n",
        "    response += new_text\n",
        "  print()\n",
        "  messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "torch_gc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTESHaFvbNTr"
      },
      "source": [
        "## Merge the LoRA adapter and optionally upload model\n",
        "\n",
        "NOTE: the Colab free version has merely 12GB RAM, where merging LoRA of a 8B model needs at least 18GB RAM, thus you **cannot** perform it in the free version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcNcHcA4bf4Z"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IMojogHbaOZF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100%|███████████████| 51.1k/51.1k [00:00<00:00, 1.87MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:08<00:00, 1.07MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 459/459 [00:00<00:00, 1.75MB/s]\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:52:33,090 >> loading file tokenizer.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:52:33,090 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:52:33,090 >> loading file special_tokens_map.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2108] 2024-06-24 14:52:33,090 >> loading file tokenizer_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer_config.json\n",
            "[WARNING|logging.py:314] 2024-06-24 14:52:33,266 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "06/24/2024 14:52:33 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
            "/home/anonymous/anaconda3/envs/nursingllm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████████| 707/707 [00:00<00:00, 3.40MB/s]\n",
            "[INFO|configuration_utils.py:733] 2024-06-24 14:52:33,773 >> loading configuration file config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\n",
            "[INFO|configuration_utils.py:796] 2024-06-24 14:52:33,774 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "06/24/2024 14:52:33 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
            "model.safetensors.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 63.4MB/s]\n",
            "[INFO|modeling_utils.py:3474] 2024-06-24 14:52:34,768 >> loading weights file model.safetensors from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/model.safetensors.index.json\n",
            "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0%|    | 10.5M/4.98G [00:02<23:32, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0%|    | 21.0M/4.98G [00:05<23:18, 3.54MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|    | 31.5M/4.98G [00:08<23:09, 3.56MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|    | 41.9M/4.98G [00:12<23:45, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|    | 52.4M/4.98G [00:14<23:26, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|    | 62.9M/4.98G [00:17<23:14, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|    | 73.4M/4.98G [00:21<23:38, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2%|    | 83.9M/4.98G [00:23<23:21, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2%|    | 94.4M/4.98G [00:26<23:09, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2%|     | 105M/4.98G [00:29<22:59, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2%|     | 115M/4.98G [00:33<23:22, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏    | 126M/4.98G [00:35<23:07, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏    | 136M/4.98G [00:38<22:57, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏    | 147M/4.98G [00:42<23:21, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏    | 157M/4.98G [00:45<23:08, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏    | 168M/4.98G [00:48<22:57, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▏    | 178M/4.98G [00:50<22:46, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▏    | 189M/4.98G [00:54<23:06, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▏    | 199M/4.98G [00:57<22:51, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▏    | 210M/4.98G [00:59<22:38, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▏    | 220M/4.98G [01:03<22:57, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▏    | 231M/4.98G [01:06<22:41, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▏    | 241M/4.98G [01:09<22:29, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▎    | 252M/4.98G [01:11<22:19, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▎    | 262M/4.98G [01:15<22:39, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▎    | 273M/4.98G [01:18<22:25, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6%|▎    | 283M/4.98G [01:20<22:14, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6%|▎    | 294M/4.98G [01:24<22:33, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6%|▎    | 304M/4.98G [01:27<22:18, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6%|▎    | 315M/4.98G [01:30<22:06, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▎    | 325M/4.98G [01:33<22:25, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▎    | 336M/4.98G [01:36<22:12, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▎    | 346M/4.98G [01:39<22:04, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▎    | 357M/4.98G [01:42<21:59, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▎    | 367M/4.98G [01:45<22:24, 3.43MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍    | 377M/4.98G [01:48<22:15, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍    | 388M/4.98G [01:51<22:10, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍    | 398M/4.98G [01:54<22:32, 3.38MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍    | 409M/4.98G [01:57<22:17, 3.42MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍    | 419M/4.98G [02:00<21:57, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▍    | 430M/4.98G [02:03<21:42, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▍    | 440M/4.98G [02:06<21:58, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▍    | 451M/4.98G [02:09<21:41, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▍    | 461M/4.98G [02:12<21:28, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▍    | 472M/4.98G [02:15<21:45, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10%|▍    | 482M/4.98G [02:18<21:29, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10%|▍    | 493M/4.98G [02:21<21:18, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10%|▌    | 503M/4.98G [02:24<21:08, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10%|▌    | 514M/4.98G [02:27<21:27, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▌    | 524M/4.98G [02:30<21:13, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▌    | 535M/4.98G [02:33<21:02, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▌    | 545M/4.98G [02:36<21:21, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▌    | 556M/4.98G [02:39<21:06, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▌    | 566M/4.98G [02:42<20:55, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▌    | 577M/4.98G [02:45<21:13, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▌    | 587M/4.98G [02:48<20:57, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▌    | 598M/4.98G [02:51<20:46, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▌    | 608M/4.98G [02:54<20:38, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▌    | 619M/4.98G [02:57<20:59, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▋    | 629M/4.98G [03:00<20:45, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▋    | 640M/4.98G [03:03<20:33, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▋    | 650M/4.98G [03:06<20:52, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▋    | 661M/4.98G [03:09<20:37, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▋    | 671M/4.98G [03:12<20:25, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14%|▋    | 682M/4.98G [03:15<20:16, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14%|▋    | 692M/4.98G [03:18<20:35, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14%|▋    | 703M/4.98G [03:21<20:22, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14%|▋    | 713M/4.98G [03:24<20:12, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▋    | 724M/4.98G [03:27<20:29, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▋    | 734M/4.98G [03:30<20:15, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▋    | 744M/4.98G [03:33<20:04, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▊    | 755M/4.98G [03:36<19:56, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▊    | 765M/4.98G [03:39<20:14, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▊    | 776M/4.98G [03:42<20:01, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▊    | 786M/4.98G [03:45<19:51, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▊    | 797M/4.98G [03:48<20:09, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▊    | 807M/4.98G [03:51<19:55, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▊    | 818M/4.98G [03:54<19:44, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|▊    | 828M/4.98G [03:57<19:51, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|▊    | 839M/4.98G [04:00<19:50, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|▊    | 849M/4.98G [04:03<19:40, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|▊    | 860M/4.98G [04:06<19:28, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|▊    | 870M/4.98G [04:09<19:45, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18%|▉    | 881M/4.98G [04:12<19:31, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18%|▉    | 891M/4.98G [04:15<19:22, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18%|▉    | 902M/4.98G [04:18<19:39, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18%|▉    | 912M/4.98G [04:21<19:25, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|▉    | 923M/4.98G [04:24<19:13, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|▉    | 933M/4.98G [04:27<19:05, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|▉    | 944M/4.98G [04:30<19:23, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|▉    | 954M/4.98G [04:33<19:10, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|▉    | 965M/4.98G [04:36<19:00, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|▉    | 975M/4.98G [04:39<19:18, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|▉    | 986M/4.98G [04:42<19:09, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|█    | 996M/4.98G [04:45<19:01, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|▊   | 1.01G/4.98G [04:48<18:53, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|▊   | 1.02G/4.98G [04:51<19:14, 3.43MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|▊   | 1.03G/4.98G [04:54<19:07, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|▊   | 1.04G/4.98G [04:57<18:59, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|▊   | 1.05G/4.98G [05:01<19:16, 3.40MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|▊   | 1.06G/4.98G [05:04<19:10, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|▊   | 1.07G/4.98G [05:07<18:51, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22%|▊   | 1.08G/4.98G [05:10<19:02, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22%|▉   | 1.09G/4.98G [05:13<18:43, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22%|▉   | 1.10G/4.98G [05:16<18:30, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22%|▉   | 1.11G/4.98G [05:19<18:19, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|▉   | 1.12G/4.98G [05:22<18:35, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|▉   | 1.13G/4.98G [05:25<18:21, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|▉   | 1.14G/4.98G [05:28<18:11, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|▉   | 1.15G/4.98G [05:31<18:26, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|▉   | 1.16G/4.98G [05:34<18:12, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|▉   | 1.17G/4.98G [05:37<18:02, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|▉   | 1.18G/4.98G [05:40<17:54, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|▉   | 1.20G/4.98G [05:43<18:10, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|▉   | 1.21G/4.98G [05:46<17:58, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|▉   | 1.22G/4.98G [05:49<17:48, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|▉   | 1.23G/4.98G [05:52<18:04, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|▉   | 1.24G/4.98G [05:55<17:50, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|█   | 1.25G/4.98G [05:58<17:41, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|█   | 1.26G/4.98G [06:01<17:36, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|█   | 1.27G/4.98G [06:04<17:52, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26%|█   | 1.28G/4.98G [06:07<17:39, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26%|█   | 1.29G/4.98G [06:10<17:29, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26%|█   | 1.30G/4.98G [06:13<17:43, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26%|█   | 1.31G/4.98G [06:16<17:30, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█   | 1.32G/4.98G [06:19<17:20, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█   | 1.33G/4.98G [06:22<17:12, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█   | 1.34G/4.98G [06:25<17:28, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█   | 1.35G/4.98G [06:28<17:17, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█   | 1.36G/4.98G [06:31<17:07, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█   | 1.37G/4.98G [06:34<17:22, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█   | 1.38G/4.98G [06:37<17:09, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█   | 1.39G/4.98G [06:40<16:59, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█▏  | 1.41G/4.98G [06:43<17:13, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█▏  | 1.42G/4.98G [06:46<17:01, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▏  | 1.43G/4.98G [06:49<16:53, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▏  | 1.44G/4.98G [06:52<16:47, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▏  | 1.45G/4.98G [06:55<17:03, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▏  | 1.46G/4.98G [06:58<16:52, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▏  | 1.47G/4.98G [07:01<16:46, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30%|█▏  | 1.48G/4.98G [07:04<16:45, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30%|█▏  | 1.49G/4.98G [07:07<16:42, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30%|█▏  | 1.50G/4.98G [07:10<16:37, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30%|█▏  | 1.51G/4.98G [07:13<16:55, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▏  | 1.52G/4.98G [07:16<16:49, 3.42MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▏  | 1.53G/4.98G [07:19<16:44, 3.43MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▏  | 1.54G/4.98G [07:22<17:03, 3.36MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▏  | 1.55G/4.98G [07:25<16:44, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▎  | 1.56G/4.98G [07:28<16:29, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▎  | 1.57G/4.98G [07:31<16:38, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▎  | 1.58G/4.98G [07:34<16:23, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▎  | 1.59G/4.98G [07:37<16:12, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▎  | 1.60G/4.98G [07:40<16:07, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▎  | 1.61G/4.98G [07:44<16:24, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33%|█▎  | 1.63G/4.98G [07:47<16:13, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33%|█▎  | 1.64G/4.98G [07:50<16:08, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33%|█▎  | 1.65G/4.98G [07:53<16:18, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33%|█▎  | 1.66G/4.98G [07:56<16:01, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▎  | 1.67G/4.98G [07:59<15:49, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▎  | 1.68G/4.98G [08:02<16:00, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▎  | 1.69G/4.98G [08:05<15:48, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▎  | 1.70G/4.98G [08:08<15:39, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▎  | 1.71G/4.98G [08:11<15:36, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▍  | 1.72G/4.98G [08:14<15:46, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▍  | 1.73G/4.98G [08:17<15:40, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▍  | 1.74G/4.98G [08:20<15:34, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▍  | 1.75G/4.98G [08:23<15:49, 3.40MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▍  | 1.76G/4.98G [08:26<15:37, 3.43MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▍  | 1.77G/4.98G [08:29<15:35, 3.43MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▍  | 1.78G/4.98G [08:32<15:29, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▍  | 1.79G/4.98G [08:35<15:47, 3.36MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▍  | 1.80G/4.98G [08:39<15:40, 3.37MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▍  | 1.81G/4.98G [08:42<15:32, 3.39MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37%|█▍  | 1.82G/4.98G [08:45<15:42, 3.34MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37%|█▍  | 1.84G/4.98G [08:48<15:21, 3.41MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37%|█▍  | 1.85G/4.98G [08:51<15:06, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37%|█▍  | 1.86G/4.98G [08:54<15:13, 3.42MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▌  | 1.87G/4.98G [08:57<14:58, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▌  | 1.88G/4.98G [09:00<14:47, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▌  | 1.89G/4.98G [09:03<14:39, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▌  | 1.90G/4.98G [09:06<14:52, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▌  | 1.91G/4.98G [09:09<14:40, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▌  | 1.92G/4.98G [09:12<14:31, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▌  | 1.93G/4.98G [09:15<14:42, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▌  | 1.94G/4.98G [09:18<14:31, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▌  | 1.95G/4.98G [09:21<14:22, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▌  | 1.96G/4.98G [09:24<14:14, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▌  | 1.97G/4.98G [09:27<14:27, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▌  | 1.98G/4.98G [09:30<14:17, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▌  | 1.99G/4.98G [09:33<14:08, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▌  | 2.00G/4.98G [09:36<14:20, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▌  | 2.01G/4.98G [09:39<14:09, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41%|█▋  | 2.02G/4.98G [09:42<14:00, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41%|█▋  | 2.03G/4.98G [09:45<13:53, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41%|█▋  | 2.04G/4.98G [09:48<14:06, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41%|█▋  | 2.06G/4.98G [09:51<13:56, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|█▋  | 2.07G/4.98G [09:54<13:47, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|█▋  | 2.08G/4.98G [09:57<13:59, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|█▋  | 2.09G/4.98G [10:00<13:48, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|█▋  | 2.10G/4.98G [10:03<13:39, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|█▋  | 2.11G/4.98G [10:06<13:52, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|█▋  | 2.12G/4.98G [10:09<13:41, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|█▋  | 2.13G/4.98G [10:12<13:32, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|█▋  | 2.14G/4.98G [10:15<13:25, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|█▋  | 2.15G/4.98G [10:18<13:36, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|█▋  | 2.16G/4.98G [10:21<13:26, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|█▋  | 2.17G/4.98G [10:24<13:18, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|█▊  | 2.18G/4.98G [10:27<13:28, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|█▊  | 2.19G/4.98G [10:30<13:18, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|█▊  | 2.20G/4.98G [10:33<13:10, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|█▊  | 2.21G/4.98G [10:36<13:03, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45%|█▊  | 2.22G/4.98G [10:39<13:14, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45%|█▊  | 2.23G/4.98G [10:42<13:08, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45%|█▊  | 2.24G/4.98G [10:45<12:55, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45%|█▊  | 2.25G/4.98G [10:48<13:05, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|█▊  | 2.26G/4.98G [10:51<12:56, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|█▊  | 2.28G/4.98G [10:54<12:48, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|█▊  | 2.29G/4.98G [10:57<12:42, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|█▊  | 2.30G/4.98G [11:00<12:53, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|█▊  | 2.31G/4.98G [11:03<12:43, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|█▊  | 2.32G/4.98G [11:06<12:37, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|█▊  | 2.33G/4.98G [11:09<12:46, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|█▉  | 2.34G/4.98G [11:12<12:36, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|█▉  | 2.35G/4.98G [11:15<12:28, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|█▉  | 2.36G/4.98G [11:18<12:41, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|█▉  | 2.37G/4.98G [11:21<12:29, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|█▉  | 2.38G/4.98G [11:24<12:20, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|█▉  | 2.39G/4.98G [11:27<12:13, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|█▉  | 2.40G/4.98G [11:30<12:23, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|█▉  | 2.41G/4.98G [11:33<12:13, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49%|█▉  | 2.42G/4.98G [11:36<12:06, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49%|█▉  | 2.43G/4.98G [11:39<12:15, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49%|█▉  | 2.44G/4.98G [11:42<12:05, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49%|█▉  | 2.45G/4.98G [11:45<11:58, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|█▉  | 2.46G/4.98G [11:48<11:51, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|█▉  | 2.47G/4.98G [11:51<12:01, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|█▉  | 2.49G/4.98G [11:54<11:52, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|██  | 2.50G/4.98G [11:57<11:45, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|██  | 2.51G/4.98G [12:00<11:54, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██  | 2.52G/4.98G [12:03<11:44, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██  | 2.53G/4.98G [12:06<11:36, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██  | 2.54G/4.98G [12:09<11:31, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██  | 2.55G/4.98G [12:12<11:41, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██  | 2.56G/4.98G [12:15<11:31, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██  | 2.57G/4.98G [12:18<11:24, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██  | 2.58G/4.98G [12:21<11:33, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██  | 2.59G/4.98G [12:24<11:23, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██  | 2.60G/4.98G [12:27<11:16, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██  | 2.61G/4.98G [12:30<11:10, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53%|██  | 2.62G/4.98G [12:33<11:19, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53%|██  | 2.63G/4.98G [12:36<11:10, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53%|██  | 2.64G/4.98G [12:39<11:03, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53%|██▏ | 2.65G/4.98G [12:42<11:11, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▏ | 2.66G/4.98G [12:45<11:02, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▏ | 2.67G/4.98G [12:48<10:55, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▏ | 2.68G/4.98G [12:51<11:03, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▏ | 2.69G/4.98G [12:54<10:54, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▏ | 2.71G/4.98G [12:57<10:46, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▏ | 2.72G/4.98G [13:00<10:40, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▏ | 2.73G/4.98G [13:03<10:49, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▏ | 2.74G/4.98G [13:06<10:40, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▏ | 2.75G/4.98G [13:09<10:34, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▏ | 2.76G/4.98G [13:12<10:42, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▏ | 2.77G/4.98G [13:15<10:33, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▏ | 2.78G/4.98G [13:18<10:25, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▏ | 2.79G/4.98G [13:21<10:20, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▎ | 2.80G/4.98G [13:24<10:30, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▎ | 2.81G/4.98G [13:27<10:18, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57%|██▎ | 2.82G/4.98G [13:30<10:12, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57%|██▎ | 2.83G/4.98G [13:33<10:19, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57%|██▎ | 2.84G/4.98G [13:36<10:11, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57%|██▎ | 2.85G/4.98G [13:39<10:04, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▎ | 2.86G/4.98G [13:42<09:58, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▎ | 2.87G/4.98G [13:45<10:06, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▎ | 2.88G/4.98G [13:48<09:58, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▎ | 2.89G/4.98G [13:51<09:52, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▎ | 2.90G/4.98G [13:54<09:59, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▎ | 2.92G/4.98G [13:57<09:50, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▎ | 2.93G/4.98G [14:00<09:43, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▎ | 2.94G/4.98G [14:03<09:38, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▎ | 2.95G/4.98G [14:06<09:45, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▍ | 2.96G/4.98G [14:09<09:37, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|██▍ | 2.97G/4.98G [14:12<09:32, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|██▍ | 2.98G/4.98G [14:15<09:38, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|██▍ | 2.99G/4.98G [14:18<09:30, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|██▍ | 3.00G/4.98G [14:21<09:23, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|██▍ | 3.01G/4.98G [14:24<09:29, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|██▍ | 3.02G/4.98G [14:27<09:21, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|██▍ | 3.03G/4.98G [14:30<09:14, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|██▍ | 3.04G/4.98G [14:33<09:08, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|██▍ | 3.05G/4.98G [14:36<09:15, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|██▍ | 3.06G/4.98G [14:39<09:07, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|██▍ | 3.07G/4.98G [14:42<09:01, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|██▍ | 3.08G/4.98G [14:45<09:07, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|██▍ | 3.09G/4.98G [14:48<08:59, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|██▍ | 3.10G/4.98G [14:51<08:53, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|██▌ | 3.11G/4.98G [14:54<08:47, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|██▌ | 3.12G/4.98G [14:57<08:54, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|██▌ | 3.14G/4.98G [15:00<08:46, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|██▌ | 3.15G/4.98G [15:03<08:40, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|██▌ | 3.16G/4.98G [15:06<08:46, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|██▌ | 3.17G/4.98G [15:09<08:38, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|██▌ | 3.18G/4.98G [15:12<08:32, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|██▌ | 3.19G/4.98G [15:15<08:27, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|██▌ | 3.20G/4.98G [15:18<08:33, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|██▌ | 3.21G/4.98G [15:21<08:25, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|██▌ | 3.22G/4.98G [15:24<08:19, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|██▌ | 3.23G/4.98G [15:27<08:25, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|██▌ | 3.24G/4.98G [15:30<08:17, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|██▌ | 3.25G/4.98G [15:33<08:11, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▌ | 3.26G/4.98G [15:36<08:16, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▋ | 3.27G/4.98G [15:39<08:08, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▋ | 3.28G/4.98G [15:42<08:02, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▋ | 3.29G/4.98G [15:45<07:57, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▋ | 3.30G/4.98G [15:48<08:02, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.31G/4.98G [15:51<07:55, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.32G/4.98G [15:54<07:49, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.33G/4.98G [15:57<07:54, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.34G/4.98G [16:00<07:47, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.36G/4.98G [16:03<07:41, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.37G/4.98G [16:06<07:36, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.38G/4.98G [16:09<07:41, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.39G/4.98G [16:12<07:35, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.40G/4.98G [16:15<07:29, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.41G/4.98G [16:18<07:34, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|██▋ | 3.42G/4.98G [16:21<07:26, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|██▊ | 3.43G/4.98G [16:24<07:20, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|██▊ | 3.44G/4.98G [16:27<07:15, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|██▊ | 3.45G/4.98G [16:30<07:20, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|██▊ | 3.46G/4.98G [16:33<07:14, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|██▊ | 3.47G/4.98G [16:36<07:08, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|██▊ | 3.48G/4.98G [16:39<07:12, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|██▊ | 3.49G/4.98G [16:42<07:05, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|██▊ | 3.50G/4.98G [16:45<06:59, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.51G/4.98G [16:48<07:03, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.52G/4.98G [16:51<06:56, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.53G/4.98G [16:54<06:50, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.54G/4.98G [16:57<06:46, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.55G/4.98G [17:00<06:50, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|██▊ | 3.57G/4.98G [17:03<06:43, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|██▊ | 3.58G/4.98G [17:06<06:38, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|██▉ | 3.59G/4.98G [17:09<06:41, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|██▉ | 3.60G/4.98G [17:12<06:36, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|██▉ | 3.61G/4.98G [17:15<06:30, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73%|██▉ | 3.62G/4.98G [17:18<06:25, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73%|██▉ | 3.63G/4.98G [17:21<06:29, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73%|██▉ | 3.64G/4.98G [17:24<06:22, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73%|██▉ | 3.65G/4.98G [17:27<06:17, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|██▉ | 3.66G/4.98G [17:30<06:20, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|██▉ | 3.67G/4.98G [17:33<06:14, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|██▉ | 3.68G/4.98G [17:36<06:08, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|██▉ | 3.69G/4.98G [17:39<06:04, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|██▉ | 3.70G/4.98G [17:42<06:07, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|██▉ | 3.71G/4.98G [17:45<06:01, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|██▉ | 3.72G/4.98G [17:48<05:56, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|███ | 3.73G/4.98G [17:51<05:59, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|███ | 3.74G/4.98G [17:54<05:53, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|███ | 3.75G/4.98G [17:57<05:48, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███ | 3.76G/4.98G [18:00<05:43, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███ | 3.77G/4.98G [18:03<05:46, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███ | 3.79G/4.98G [18:06<05:40, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███ | 3.80G/4.98G [18:09<05:35, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███ | 3.81G/4.98G [18:12<05:38, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77%|███ | 3.82G/4.98G [18:15<05:33, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77%|███ | 3.83G/4.98G [18:18<05:27, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77%|███ | 3.84G/4.98G [18:21<05:29, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77%|███ | 3.85G/4.98G [18:24<05:23, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███ | 3.86G/4.98G [18:27<05:18, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███ | 3.87G/4.98G [18:30<05:13, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███ | 3.88G/4.98G [18:33<05:16, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███▏| 3.89G/4.98G [18:36<05:10, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███▏| 3.90G/4.98G [18:39<05:05, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▏| 3.91G/4.98G [18:42<05:08, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▏| 3.92G/4.98G [18:45<05:02, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▏| 3.93G/4.98G [18:48<04:57, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▏| 3.94G/4.98G [18:51<04:52, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▏| 3.95G/4.98G [18:54<04:55, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|███▏| 3.96G/4.98G [18:57<04:49, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|███▏| 3.97G/4.98G [19:00<04:45, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|███▏| 3.98G/4.98G [19:03<04:46, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|███▏| 4.00G/4.98G [19:06<04:41, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|███▏| 4.01G/4.98G [19:09<04:36, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81%|███▏| 4.02G/4.98G [19:12<04:32, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81%|███▏| 4.03G/4.98G [19:15<04:34, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81%|███▏| 4.04G/4.98G [19:18<04:29, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81%|███▎| 4.05G/4.98G [19:21<04:24, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|███▎| 4.06G/4.98G [19:24<04:25, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|███▎| 4.07G/4.98G [19:27<04:20, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|███▎| 4.08G/4.98G [19:30<04:15, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|███▎| 4.09G/4.98G [19:33<04:16, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|███▎| 4.10G/4.98G [19:36<04:11, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|███▎| 4.11G/4.98G [19:39<04:06, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|███▎| 4.12G/4.98G [19:42<04:02, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|███▎| 4.13G/4.98G [19:45<04:03, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|███▎| 4.14G/4.98G [19:48<03:58, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|███▎| 4.15G/4.98G [19:51<03:54, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|███▎| 4.16G/4.98G [19:54<03:55, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|███▎| 4.17G/4.98G [19:57<03:50, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|███▎| 4.18G/4.98G [20:00<03:45, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|███▎| 4.19G/4.98G [20:03<03:41, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|███▍| 4.20G/4.98G [20:06<03:42, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85%|███▍| 4.22G/4.98G [20:09<03:37, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85%|███▍| 4.23G/4.98G [20:12<03:33, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85%|███▍| 4.24G/4.98G [20:15<03:35, 3.44MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85%|███▍| 4.25G/4.98G [20:18<03:29, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|███▍| 4.26G/4.98G [20:21<03:25, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|███▍| 4.27G/4.98G [20:24<03:21, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|███▍| 4.28G/4.98G [20:27<03:21, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|███▍| 4.29G/4.98G [20:30<03:16, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|███▍| 4.30G/4.98G [20:33<03:12, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|███▍| 4.31G/4.98G [20:36<03:12, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|███▍| 4.32G/4.98G [20:39<03:08, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|███▍| 4.33G/4.98G [20:42<03:03, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|███▍| 4.34G/4.98G [20:45<03:03, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|███▍| 4.35G/4.98G [20:48<02:59, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|███▌| 4.36G/4.98G [20:51<02:54, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|███▌| 4.37G/4.98G [20:54<02:51, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|███▌| 4.38G/4.98G [20:57<02:51, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|███▌| 4.39G/4.98G [21:00<02:46, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|███▌| 4.40G/4.98G [21:03<02:42, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89%|███▌| 4.41G/4.98G [21:06<02:42, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89%|███▌| 4.42G/4.98G [21:09<02:38, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89%|███▌| 4.44G/4.98G [21:12<02:34, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89%|███▌| 4.45G/4.98G [21:15<02:30, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|███▌| 4.46G/4.98G [21:18<02:30, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|███▌| 4.47G/4.98G [21:21<02:25, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|███▌| 4.48G/4.98G [21:24<02:21, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|███▌| 4.49G/4.98G [21:27<02:21, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|███▌| 4.50G/4.98G [21:30<02:17, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|███▌| 4.51G/4.98G [21:33<02:13, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|███▋| 4.52G/4.98G [21:36<02:09, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|███▋| 4.53G/4.98G [21:39<02:08, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|███▋| 4.54G/4.98G [21:42<02:04, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|███▋| 4.55G/4.98G [21:45<02:01, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|███▋| 4.56G/4.98G [21:48<02:00, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|███▋| 4.57G/4.98G [21:51<01:56, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|███▋| 4.58G/4.98G [21:54<01:52, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|███▋| 4.59G/4.98G [21:57<01:48, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|███▋| 4.60G/4.98G [22:00<01:47, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93%|███▋| 4.61G/4.98G [22:03<01:43, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93%|███▋| 4.62G/4.98G [22:06<01:40, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93%|███▋| 4.63G/4.98G [22:09<01:38, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93%|███▋| 4.65G/4.98G [22:12<01:35, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|███▋| 4.66G/4.98G [22:15<01:31, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|███▊| 4.67G/4.98G [22:18<01:30, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|███▊| 4.68G/4.98G [22:21<01:26, 3.48MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|███▊| 4.69G/4.98G [22:24<01:22, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|███▊| 4.70G/4.98G [22:27<01:19, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|███▊| 4.71G/4.98G [22:30<01:17, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|███▊| 4.72G/4.98G [22:33<01:13, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|███▊| 4.73G/4.98G [22:36<01:10, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|███▊| 4.74G/4.98G [22:39<01:08, 3.45MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|███▊| 4.75G/4.98G [22:42<01:04, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|███▊| 4.76G/4.98G [22:45<01:01, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|███▊| 4.77G/4.98G [22:48<00:58, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|███▊| 4.78G/4.98G [22:51<00:56, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|███▊| 4.79G/4.98G [22:54<00:52, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|███▊| 4.80G/4.98G [22:57<00:49, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97%|███▊| 4.81G/4.98G [23:00<00:47, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97%|███▉| 4.82G/4.98G [23:03<00:43, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97%|███▉| 4.83G/4.98G [23:06<00:40, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97%|███▉| 4.84G/4.98G [23:09<00:37, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|███▉| 4.85G/4.98G [23:12<00:35, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|███▉| 4.87G/4.98G [23:15<00:32, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|███▉| 4.88G/4.98G [23:18<00:28, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|███▉| 4.89G/4.98G [23:21<00:25, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|███▉| 4.90G/4.98G [23:24<00:22, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|███▉| 4.91G/4.98G [23:27<00:20, 3.47MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|███▉| 4.92G/4.98G [23:30<00:16, 3.50MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|███▉| 4.93G/4.98G [23:33<00:13, 3.52MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|███▉| 4.94G/4.98G [23:36<00:10, 3.46MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|███▉| 4.95G/4.98G [23:39<00:07, 3.49MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100%|███▉| 4.96G/4.98G [23:42<00:04, 3.51MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100%|███▉| 4.97G/4.98G [23:45<00:01, 3.53MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100%|████| 4.98G/4.98G [23:47<00:00, 3.49MB/s]\u001b[A\n",
            "Downloading shards:  25%|█████▎               | 1/4 [23:48<1:11:26, 1428.69s/it]\n",
            "model-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   0%|    | 10.5M/5.00G [00:02<23:16, 3.57MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   0%|    | 21.0M/5.00G [00:05<23:14, 3.57MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|    | 31.5M/5.00G [00:08<23:11, 3.57MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|    | 41.9M/5.00G [00:11<23:48, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|    | 52.4M/5.00G [00:14<23:31, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|    | 62.9M/5.00G [00:17<23:19, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|    | 73.4M/5.00G [00:20<23:44, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2%|    | 83.9M/5.00G [00:23<23:27, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2%|    | 94.4M/5.00G [00:26<23:15, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2%|     | 105M/5.00G [00:29<23:05, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2%|     | 115M/5.00G [00:32<23:29, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏    | 126M/5.00G [00:35<23:14, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏    | 136M/5.00G [00:38<23:02, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏    | 147M/5.00G [00:41<23:23, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏    | 157M/5.00G [00:44<23:07, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏    | 168M/5.00G [00:47<22:54, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▏    | 178M/5.00G [00:50<22:46, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▏    | 189M/5.00G [00:53<23:07, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▏    | 199M/5.00G [00:56<22:52, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▏    | 210M/5.00G [00:59<22:41, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▏    | 220M/5.00G [01:02<23:01, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▏    | 231M/5.00G [01:05<22:45, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▏    | 241M/5.00G [01:08<22:34, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▎    | 252M/5.00G [01:11<22:24, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▎    | 262M/5.00G [01:14<22:46, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▎    | 273M/5.00G [01:17<22:31, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6%|▎    | 283M/5.00G [01:20<22:20, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6%|▎    | 294M/5.00G [01:23<22:40, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6%|▎    | 304M/5.00G [01:26<22:24, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6%|▎    | 315M/5.00G [01:29<22:13, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▎    | 325M/5.00G [01:32<22:32, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▎    | 336M/5.00G [01:35<22:18, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▎    | 346M/5.00G [01:38<22:05, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▎    | 357M/5.00G [01:41<21:56, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▎    | 367M/5.00G [01:44<22:17, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍    | 377M/5.00G [01:47<22:03, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍    | 388M/5.00G [01:50<21:51, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍    | 398M/5.00G [01:54<22:10, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍    | 409M/5.00G [01:56<21:55, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍    | 419M/5.00G [01:59<21:43, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▍    | 430M/5.00G [02:02<21:34, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▍    | 440M/5.00G [02:05<21:55, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▍    | 451M/5.00G [02:08<21:40, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▍    | 461M/5.00G [02:11<21:29, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▍    | 472M/5.00G [02:14<21:48, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▍    | 482M/5.00G [02:17<21:34, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▍    | 493M/5.00G [02:20<21:22, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▌    | 503M/5.00G [02:23<21:13, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▌    | 514M/5.00G [02:27<21:40, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▌    | 524M/5.00G [02:29<21:24, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11%|▌    | 535M/5.00G [02:32<21:12, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11%|▌    | 545M/5.00G [02:36<21:32, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11%|▌    | 556M/5.00G [02:38<21:16, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11%|▌    | 566M/5.00G [02:41<21:04, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▌    | 577M/5.00G [02:45<21:22, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▌    | 587M/5.00G [02:48<21:06, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▌    | 598M/5.00G [02:50<20:54, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▌    | 608M/5.00G [02:53<20:44, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▌    | 619M/5.00G [02:57<21:04, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▋    | 629M/5.00G [02:59<20:50, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▋    | 640M/5.00G [03:02<20:39, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▋    | 650M/5.00G [03:06<20:57, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▋    | 661M/5.00G [03:09<20:43, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▋    | 671M/5.00G [03:11<20:31, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▋    | 682M/5.00G [03:14<20:23, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▋    | 692M/5.00G [03:18<20:42, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▋    | 703M/5.00G [03:20<20:28, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▋    | 713M/5.00G [03:23<20:18, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▋    | 724M/5.00G [03:27<20:36, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15%|▋    | 734M/5.00G [03:30<20:21, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15%|▋    | 744M/5.00G [03:32<20:11, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15%|▊    | 755M/5.00G [03:35<20:04, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15%|▊    | 765M/5.00G [03:39<20:22, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▊    | 776M/5.00G [03:41<20:08, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▊    | 786M/5.00G [03:44<19:58, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▊    | 797M/5.00G [03:48<20:15, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▊    | 807M/5.00G [03:51<20:01, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▊    | 818M/5.00G [03:53<19:50, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|▊    | 828M/5.00G [03:56<19:42, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|▊    | 839M/5.00G [04:00<20:00, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|▊    | 849M/5.00G [04:02<19:46, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|▊    | 860M/5.00G [04:05<19:36, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|▊    | 870M/5.00G [04:09<19:55, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|▉    | 881M/5.00G [04:12<19:40, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|▉    | 891M/5.00G [04:14<19:29, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|▉    | 902M/5.00G [04:18<19:45, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|▉    | 912M/5.00G [04:21<19:31, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|▉    | 923M/5.00G [04:23<19:21, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19%|▉    | 933M/5.00G [04:26<19:12, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19%|▉    | 944M/5.00G [04:30<19:30, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19%|▉    | 954M/5.00G [04:33<19:17, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19%|▉    | 965M/5.00G [04:35<19:06, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|▉    | 975M/5.00G [04:39<19:24, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|▉    | 986M/5.00G [04:42<19:10, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|▉    | 996M/5.00G [04:44<18:59, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|▊   | 1.01G/5.00G [04:47<18:51, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|▊   | 1.02G/5.00G [04:51<19:08, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|▊   | 1.03G/5.00G [04:54<18:56, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|▊   | 1.04G/5.00G [04:56<18:46, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|▊   | 1.05G/5.00G [05:00<19:01, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|▊   | 1.06G/5.00G [05:03<18:48, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|▊   | 1.07G/5.00G [05:05<18:38, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|▊   | 1.08G/5.00G [05:08<18:30, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|▊   | 1.09G/5.00G [05:12<18:47, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|▉   | 1.10G/5.00G [05:14<18:34, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|▉   | 1.11G/5.00G [05:17<18:25, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|▉   | 1.12G/5.00G [05:21<18:41, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|▉   | 1.13G/5.00G [05:24<18:27, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|▉   | 1.14G/5.00G [05:26<18:17, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|▉   | 1.15G/5.00G [05:30<18:22, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|▉   | 1.16G/5.00G [05:33<18:23, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|▉   | 1.17G/5.00G [05:35<18:11, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24%|▉   | 1.18G/5.00G [05:38<18:03, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24%|▉   | 1.20G/5.00G [05:42<18:19, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24%|▉   | 1.21G/5.00G [05:45<18:06, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24%|▉   | 1.22G/5.00G [05:47<17:56, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|▉   | 1.23G/5.00G [05:51<18:11, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|▉   | 1.24G/5.00G [05:54<17:58, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|▉   | 1.25G/5.00G [05:56<17:48, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|█   | 1.26G/5.00G [05:59<17:39, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|█   | 1.27G/5.00G [06:03<17:56, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█   | 1.28G/5.00G [06:06<17:44, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█   | 1.29G/5.00G [06:08<17:34, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█   | 1.30G/5.00G [06:12<17:49, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█   | 1.31G/5.00G [06:15<17:37, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█   | 1.32G/5.00G [06:17<17:26, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█   | 1.33G/5.00G [06:20<17:19, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█   | 1.34G/5.00G [06:24<17:34, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█   | 1.35G/5.00G [06:27<17:23, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█   | 1.36G/5.00G [06:29<17:13, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█   | 1.37G/5.00G [06:33<17:28, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28%|█   | 1.38G/5.00G [06:36<17:15, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28%|█   | 1.39G/5.00G [06:38<17:06, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28%|█   | 1.41G/5.00G [06:41<16:58, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28%|█▏  | 1.42G/5.00G [06:45<17:13, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▏  | 1.43G/5.00G [06:48<17:01, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▏  | 1.44G/5.00G [06:50<16:52, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▏  | 1.45G/5.00G [06:54<17:06, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▏  | 1.46G/5.00G [06:57<16:54, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▏  | 1.47G/5.00G [06:59<16:44, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▏  | 1.48G/5.00G [07:03<16:58, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▏  | 1.49G/5.00G [07:06<16:45, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▏  | 1.50G/5.00G [07:08<16:36, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▏  | 1.51G/5.00G [07:11<16:28, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▏  | 1.52G/5.00G [07:15<16:43, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▏  | 1.53G/5.00G [07:18<16:32, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▏  | 1.54G/5.00G [07:20<16:23, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▏  | 1.55G/5.00G [07:24<16:36, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▏  | 1.56G/5.00G [07:27<16:24, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▎  | 1.57G/5.00G [07:29<16:15, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32%|█▎  | 1.58G/5.00G [07:32<16:07, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32%|█▎  | 1.59G/5.00G [07:36<16:22, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32%|█▎  | 1.60G/5.00G [07:39<16:11, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32%|█▎  | 1.61G/5.00G [07:41<16:02, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▎  | 1.63G/5.00G [07:45<16:15, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▎  | 1.64G/5.00G [07:48<16:03, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▎  | 1.65G/5.00G [07:50<15:54, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▎  | 1.66G/5.00G [07:53<15:46, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▎  | 1.67G/5.00G [07:57<16:01, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▎  | 1.68G/5.00G [08:00<15:50, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▎  | 1.69G/5.00G [08:02<15:41, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▎  | 1.70G/5.00G [08:05<15:34, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▎  | 1.71G/5.00G [08:09<15:48, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▍  | 1.72G/5.00G [08:11<15:37, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▍  | 1.73G/5.00G [08:14<15:29, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▍  | 1.74G/5.00G [08:18<15:41, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▍  | 1.75G/5.00G [08:20<15:30, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▍  | 1.76G/5.00G [08:23<15:21, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▍  | 1.77G/5.00G [08:26<15:14, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▍  | 1.78G/5.00G [08:30<15:27, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▍  | 1.79G/5.00G [08:32<15:17, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▍  | 1.80G/5.00G [08:35<15:08, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▍  | 1.81G/5.00G [08:39<15:21, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▍  | 1.82G/5.00G [08:42<15:11, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37%|█▍  | 1.84G/5.00G [08:44<15:01, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37%|█▍  | 1.85G/5.00G [08:47<14:54, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37%|█▍  | 1.86G/5.00G [08:51<15:07, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37%|█▍  | 1.87G/5.00G [08:53<14:56, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▌  | 1.88G/5.00G [08:56<14:47, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▌  | 1.89G/5.00G [09:00<15:00, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▌  | 1.90G/5.00G [09:03<14:48, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▌  | 1.91G/5.00G [09:05<14:39, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▌  | 1.92G/5.00G [09:08<14:32, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▌  | 1.93G/5.00G [09:12<14:45, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▌  | 1.94G/5.00G [09:14<14:35, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▌  | 1.95G/5.00G [09:17<14:26, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▌  | 1.96G/5.00G [09:21<14:38, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▌  | 1.97G/5.00G [09:23<14:27, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|█▌  | 1.98G/5.00G [09:26<14:18, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|█▌  | 1.99G/5.00G [09:30<14:30, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|█▌  | 2.00G/5.00G [09:33<14:19, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|█▌  | 2.01G/5.00G [09:35<14:10, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|█▌  | 2.02G/5.00G [09:38<14:03, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41%|█▋  | 2.03G/5.00G [09:42<14:15, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41%|█▋  | 2.04G/5.00G [09:45<14:07, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41%|█▋  | 2.06G/5.00G [09:47<13:58, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41%|█▋  | 2.07G/5.00G [09:51<14:09, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|█▋  | 2.08G/5.00G [09:54<13:58, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|█▋  | 2.09G/5.00G [09:56<13:49, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|█▋  | 2.10G/5.00G [09:59<13:42, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|█▋  | 2.11G/5.00G [10:03<13:54, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|█▋  | 2.12G/5.00G [10:06<13:44, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|█▋  | 2.13G/5.00G [10:08<13:36, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|█▋  | 2.14G/5.00G [10:12<13:47, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|█▋  | 2.15G/5.00G [10:15<13:36, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|█▋  | 2.16G/5.00G [10:17<13:28, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|█▋  | 2.17G/5.00G [10:20<13:21, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|█▋  | 2.18G/5.00G [10:24<13:33, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|█▊  | 2.19G/5.00G [10:27<13:22, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|█▊  | 2.20G/5.00G [10:29<13:15, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|█▊  | 2.21G/5.00G [10:33<13:26, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|█▊  | 2.22G/5.00G [10:36<13:15, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|█▊  | 2.23G/5.00G [10:38<13:07, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|█▊  | 2.24G/5.00G [10:41<13:00, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|█▊  | 2.25G/5.00G [10:45<13:16, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|█▊  | 2.26G/5.00G [10:48<13:01, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|█▊  | 2.28G/5.00G [10:50<12:53, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|█▊  | 2.29G/5.00G [10:54<13:04, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|█▊  | 2.30G/5.00G [10:57<12:54, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|█▊  | 2.31G/5.00G [10:59<12:46, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|█▊  | 2.32G/5.00G [11:03<12:55, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|█▊  | 2.33G/5.00G [11:06<12:45, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|█▊  | 2.34G/5.00G [11:09<12:37, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|█▉  | 2.35G/5.00G [11:11<12:31, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|█▉  | 2.36G/5.00G [11:15<12:41, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|█▉  | 2.37G/5.00G [11:18<12:32, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|█▉  | 2.38G/5.00G [11:20<12:24, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|█▉  | 2.39G/5.00G [11:24<12:34, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|█▉  | 2.40G/5.00G [11:27<12:24, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|█▉  | 2.41G/5.00G [11:30<12:21, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|█▉  | 2.42G/5.00G [11:32<12:13, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|█▉  | 2.43G/5.00G [11:35<12:07, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|█▉  | 2.44G/5.00G [11:39<12:17, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|█▉  | 2.45G/5.00G [11:42<12:08, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|█▉  | 2.46G/5.00G [11:44<12:02, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|█▉  | 2.47G/5.00G [11:48<12:11, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50%|█▉  | 2.49G/5.00G [11:51<12:01, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50%|█▉  | 2.50G/5.00G [11:54<11:53, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50%|██  | 2.51G/5.00G [11:56<11:49, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50%|██  | 2.52G/5.00G [12:00<11:55, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██  | 2.53G/5.00G [12:03<11:46, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██  | 2.54G/5.00G [12:05<11:39, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██  | 2.55G/5.00G [12:09<11:48, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██  | 2.56G/5.00G [12:12<11:39, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██  | 2.57G/5.00G [12:15<11:32, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██  | 2.58G/5.00G [12:17<11:25, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██  | 2.59G/5.00G [12:21<11:35, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██  | 2.60G/5.00G [12:24<11:26, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██  | 2.61G/5.00G [12:26<11:19, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██  | 2.62G/5.00G [12:30<11:27, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██  | 2.63G/5.00G [12:33<11:18, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██  | 2.64G/5.00G [12:36<11:10, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██  | 2.65G/5.00G [12:38<11:04, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██▏ | 2.66G/5.00G [12:41<10:59, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██▏ | 2.67G/5.00G [12:44<10:55, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54%|██▏ | 2.68G/5.00G [12:47<10:52, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54%|██▏ | 2.69G/5.00G [12:50<11:02, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54%|██▏ | 2.71G/5.00G [12:53<10:54, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54%|██▏ | 2.72G/5.00G [12:56<10:47, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▏ | 2.73G/5.00G [12:59<10:56, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▏ | 2.74G/5.00G [13:02<10:47, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▏ | 2.75G/5.00G [13:05<10:40, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▏ | 2.76G/5.00G [13:08<10:34, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▏ | 2.77G/5.00G [13:11<10:43, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▏ | 2.78G/5.00G [13:14<10:34, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▏ | 2.79G/5.00G [13:17<10:29, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▏ | 2.80G/5.00G [13:20<10:22, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▏ | 2.81G/5.00G [13:23<10:17, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▎ | 2.82G/5.00G [13:26<10:13, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▎ | 2.83G/5.00G [13:29<10:09, 3.56MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▎ | 2.84G/5.00G [13:32<10:19, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▎ | 2.85G/5.00G [13:35<10:12, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▎ | 2.86G/5.00G [13:38<10:06, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▎ | 2.87G/5.00G [13:41<10:14, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58%|██▎ | 2.88G/5.00G [13:44<10:05, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58%|██▎ | 2.89G/5.00G [13:47<10:00, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58%|██▎ | 2.90G/5.00G [13:50<09:57, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58%|██▎ | 2.92G/5.00G [13:53<09:48, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▎ | 2.93G/5.00G [13:56<09:43, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▎ | 2.94G/5.00G [13:59<09:40, 3.56MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▎ | 2.95G/5.00G [14:02<09:49, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▎ | 2.96G/5.00G [14:05<09:42, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▎ | 2.97G/5.00G [14:08<09:36, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▍ | 2.98G/5.00G [14:11<09:43, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▍ | 2.99G/5.00G [14:14<09:35, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▍ | 3.00G/5.00G [14:17<09:28, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▍ | 3.01G/5.00G [14:20<09:23, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▍ | 3.02G/5.00G [14:23<09:30, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|██▍ | 3.03G/5.00G [14:26<09:22, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|██▍ | 3.04G/5.00G [14:29<09:37, 3.39MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|██▍ | 3.05G/5.00G [14:32<09:25, 3.44MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|██▍ | 3.06G/5.00G [14:35<09:16, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|██▍ | 3.07G/5.00G [14:38<09:21, 3.43MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|██▍ | 3.08G/5.00G [14:41<09:11, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|██▍ | 3.09G/5.00G [14:44<09:04, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|██▍ | 3.10G/5.00G [14:47<08:58, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|██▍ | 3.11G/5.00G [14:50<09:05, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|██▍ | 3.12G/5.00G [14:53<08:57, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63%|██▌ | 3.14G/5.00G [14:56<08:50, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63%|██▌ | 3.15G/5.00G [14:59<08:56, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63%|██▌ | 3.16G/5.00G [15:02<08:48, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63%|██▌ | 3.17G/5.00G [15:05<08:42, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|██▌ | 3.18G/5.00G [15:08<08:36, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|██▌ | 3.19G/5.00G [15:11<08:42, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|██▌ | 3.20G/5.00G [15:14<08:35, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|██▌ | 3.21G/5.00G [15:17<08:29, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|██▌ | 3.22G/5.00G [15:20<08:34, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|██▌ | 3.23G/5.00G [15:23<08:26, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|██▌ | 3.24G/5.00G [15:26<08:20, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|██▌ | 3.25G/5.00G [15:29<08:15, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|██▌ | 3.26G/5.00G [15:32<08:21, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|██▌ | 3.27G/5.00G [15:35<08:14, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|██▋ | 3.28G/5.00G [15:38<08:08, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|██▋ | 3.29G/5.00G [15:41<08:03, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|██▋ | 3.30G/5.00G [15:44<07:58, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|██▋ | 3.31G/5.00G [15:47<07:54, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|██▋ | 3.32G/5.00G [15:50<07:52, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|██▋ | 3.33G/5.00G [15:53<07:58, 3.48MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|██▋ | 3.34G/5.00G [15:56<07:52, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|██▋ | 3.36G/5.00G [15:59<07:46, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|██▋ | 3.37G/5.00G [16:02<07:41, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|██▋ | 3.38G/5.00G [16:05<07:47, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|██▋ | 3.39G/5.00G [16:08<07:40, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|██▋ | 3.40G/5.00G [16:11<07:35, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|██▋ | 3.41G/5.00G [16:14<07:30, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|██▋ | 3.42G/5.00G [16:17<07:35, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|██▋ | 3.43G/5.00G [16:20<07:28, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|██▊ | 3.44G/5.00G [16:23<07:23, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|██▊ | 3.45G/5.00G [16:26<07:28, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|██▊ | 3.46G/5.00G [16:29<07:20, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|██▊ | 3.47G/5.00G [16:32<07:14, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|██▊ | 3.48G/5.00G [16:35<07:19, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|██▊ | 3.49G/5.00G [16:38<07:12, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|██▊ | 3.50G/5.00G [16:41<07:06, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|██▊ | 3.51G/5.00G [16:44<07:01, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|██▊ | 3.52G/5.00G [16:47<07:06, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|██▊ | 3.53G/5.00G [16:50<06:59, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|██▊ | 3.54G/5.00G [16:53<06:54, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|██▊ | 3.55G/5.00G [16:56<06:58, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|██▊ | 3.57G/5.00G [16:59<06:51, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|██▊ | 3.58G/5.00G [17:02<06:45, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|██▊ | 3.59G/5.00G [17:05<06:40, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|██▉ | 3.60G/5.00G [17:08<06:44, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|██▉ | 3.61G/5.00G [17:11<06:38, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|██▉ | 3.62G/5.00G [17:14<06:32, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|██▉ | 3.63G/5.00G [17:17<06:36, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|██▉ | 3.64G/5.00G [17:20<06:29, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|██▉ | 3.65G/5.00G [17:23<06:24, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|██▉ | 3.66G/5.00G [17:26<06:19, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|██▉ | 3.67G/5.00G [17:29<06:24, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|██▉ | 3.68G/5.00G [17:32<06:17, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|██▉ | 3.69G/5.00G [17:35<06:12, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|██▉ | 3.70G/5.00G [17:38<06:15, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|██▉ | 3.71G/5.00G [17:41<06:08, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|██▉ | 3.72G/5.00G [17:44<06:03, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|██▉ | 3.73G/5.00G [17:47<06:06, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|██▉ | 3.74G/5.00G [17:50<05:59, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|███ | 3.75G/5.00G [17:53<05:55, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|███ | 3.76G/5.00G [17:56<05:50, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███ | 3.77G/5.00G [17:59<05:53, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███ | 3.79G/5.00G [18:02<05:47, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███ | 3.80G/5.00G [18:05<05:42, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███ | 3.81G/5.00G [18:08<05:45, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███ | 3.82G/5.00G [18:11<05:38, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███ | 3.83G/5.00G [18:14<05:33, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███ | 3.84G/5.00G [18:17<05:29, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███ | 3.85G/5.00G [18:20<05:32, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███ | 3.86G/5.00G [18:23<05:26, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███ | 3.87G/5.00G [18:26<05:21, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███ | 3.88G/5.00G [18:29<05:23, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███ | 3.89G/5.00G [18:32<05:18, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███ | 3.90G/5.00G [18:35<05:13, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███▏| 3.91G/5.00G [18:38<05:08, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███▏| 3.92G/5.00G [18:41<05:11, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▏| 3.93G/5.00G [18:44<05:05, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▏| 3.94G/5.00G [18:47<05:00, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▏| 3.95G/5.00G [18:50<04:56, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▏| 3.96G/5.00G [18:53<04:59, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▏| 3.97G/5.00G [18:56<04:53, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|███▏| 3.98G/5.00G [18:59<04:49, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|███▏| 4.00G/5.00G [19:02<04:51, 3.44MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|███▏| 4.01G/5.00G [19:05<04:44, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|███▏| 4.02G/5.00G [19:08<04:39, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|███▏| 4.03G/5.00G [19:11<04:35, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|███▏| 4.04G/5.00G [19:14<04:37, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|███▏| 4.05G/5.00G [19:17<04:32, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|███▏| 4.06G/5.00G [19:20<04:28, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|███▎| 4.07G/5.00G [19:23<04:28, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|███▎| 4.08G/5.00G [19:26<04:23, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|███▎| 4.09G/5.00G [19:29<04:18, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|███▎| 4.10G/5.00G [19:32<04:14, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|███▎| 4.11G/5.00G [19:35<04:16, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|███▎| 4.12G/5.00G [19:38<04:11, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|███▎| 4.13G/5.00G [19:41<04:06, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|███▎| 4.14G/5.00G [19:44<04:07, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|███▎| 4.15G/5.00G [19:47<04:02, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|███▎| 4.16G/5.00G [19:50<03:58, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|███▎| 4.17G/5.00G [19:53<03:54, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84%|███▎| 4.18G/5.00G [19:56<03:55, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84%|███▎| 4.19G/5.00G [19:59<03:50, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84%|███▎| 4.20G/5.00G [20:02<03:46, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84%|███▎| 4.22G/5.00G [20:05<03:42, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|███▍| 4.23G/5.00G [20:08<03:38, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|███▍| 4.24G/5.00G [20:11<03:39, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|███▍| 4.25G/5.00G [20:14<03:34, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|███▍| 4.26G/5.00G [20:17<03:30, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|███▍| 4.27G/5.00G [20:20<03:27, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|███▍| 4.28G/5.00G [20:23<03:27, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|███▍| 4.29G/5.00G [20:26<03:23, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|███▍| 4.30G/5.00G [20:29<03:19, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|███▍| 4.31G/5.00G [20:32<03:15, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|███▍| 4.32G/5.00G [20:35<03:12, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|███▍| 4.33G/5.00G [20:38<03:12, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|███▍| 4.34G/5.00G [20:41<03:08, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|███▍| 4.35G/5.00G [20:44<03:04, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|███▍| 4.36G/5.00G [20:47<03:04, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|███▍| 4.37G/5.00G [20:50<02:59, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88%|███▌| 4.38G/5.00G [20:53<02:55, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88%|███▌| 4.39G/5.00G [20:56<02:52, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88%|███▌| 4.40G/5.00G [20:59<02:52, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88%|███▌| 4.41G/5.00G [21:02<02:47, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|███▌| 4.42G/5.00G [21:05<02:43, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|███▌| 4.44G/5.00G [21:08<02:39, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|███▌| 4.45G/5.00G [21:11<02:39, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|███▌| 4.46G/5.00G [21:14<02:35, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|███▌| 4.47G/5.00G [21:17<02:31, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|███▌| 4.48G/5.00G [21:20<02:31, 3.44MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|███▌| 4.49G/5.00G [21:23<02:26, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|███▌| 4.50G/5.00G [21:26<02:22, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|███▌| 4.51G/5.00G [21:29<02:18, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|███▌| 4.52G/5.00G [21:32<02:18, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|███▌| 4.53G/5.00G [21:35<02:14, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|███▋| 4.54G/5.00G [21:38<02:10, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|███▋| 4.55G/5.00G [21:41<02:09, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|███▋| 4.56G/5.00G [21:44<02:05, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|███▋| 4.57G/5.00G [21:47<02:02, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|███▋| 4.58G/5.00G [21:50<01:58, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|███▋| 4.59G/5.00G [21:53<01:57, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|███▋| 4.60G/5.00G [21:56<01:53, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|███▋| 4.61G/5.00G [21:59<01:49, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|███▋| 4.62G/5.00G [22:02<01:48, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93%|███▋| 4.63G/5.00G [22:05<01:45, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93%|███▋| 4.65G/5.00G [22:08<01:40, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93%|███▋| 4.66G/5.00G [22:11<01:37, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93%|███▋| 4.67G/5.00G [22:14<01:36, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|███▋| 4.68G/5.00G [22:17<01:32, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|███▋| 4.69G/5.00G [22:20<01:28, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|███▊| 4.70G/5.00G [22:23<01:25, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|███▊| 4.71G/5.00G [22:26<01:24, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|███▊| 4.72G/5.00G [22:29<01:20, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|███▊| 4.73G/5.00G [22:32<01:16, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|███▊| 4.74G/5.00G [22:35<01:15, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|███▊| 4.75G/5.00G [22:38<01:11, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|███▊| 4.76G/5.00G [22:41<01:08, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|███▊| 4.77G/5.00G [22:44<01:04, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|███▊| 4.78G/5.00G [22:47<01:01, 3.54MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|███▊| 4.79G/5.00G [22:50<00:59, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|███▊| 4.80G/5.00G [22:53<00:56, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|███▊| 4.81G/5.00G [22:56<00:53, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|███▊| 4.82G/5.00G [22:59<00:51, 3.45MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97%|███▊| 4.83G/5.00G [23:02<00:47, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97%|███▉| 4.84G/5.00G [23:05<00:44, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97%|███▉| 4.85G/5.00G [23:08<00:41, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97%|███▉| 4.87G/5.00G [23:11<00:38, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|███▉| 4.88G/5.00G [23:14<00:35, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|███▉| 4.89G/5.00G [23:17<00:32, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|███▉| 4.90G/5.00G [23:20<00:29, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|███▉| 4.91G/5.00G [23:23<00:26, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|███▉| 4.92G/5.00G [23:26<00:23, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|███▉| 4.93G/5.00G [23:29<00:20, 3.53MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|███▉| 4.94G/5.00G [23:32<00:17, 3.47MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|███▉| 4.95G/5.00G [23:35<00:14, 3.50MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|███▉| 4.96G/5.00G [23:38<00:11, 3.52MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|███▉| 4.97G/5.00G [23:41<00:08, 3.46MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100%|███▉| 4.98G/5.00G [23:44<00:05, 3.49MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100%|███▉| 4.99G/5.00G [23:47<00:02, 3.51MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100%|████| 5.00G/5.00G [23:49<00:00, 3.50MB/s]\u001b[A\n",
            "Downloading shards:  50%|███████████▌           | 2/4 [47:39<47:39, 1429.67s/it]\n",
            "model-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0%|    | 10.5M/4.92G [00:02<22:51, 3.58MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0%|    | 21.0M/4.92G [00:05<22:50, 3.57MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|    | 31.5M/4.92G [00:09<23:39, 3.44MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|    | 41.9M/4.92G [00:11<23:17, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|    | 52.4M/4.92G [00:14<23:02, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|    | 62.9M/4.92G [00:18<23:25, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|    | 73.4M/4.92G [00:21<23:07, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2%|    | 83.9M/4.92G [00:24<23:05, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2%|    | 94.4M/4.92G [00:26<22:42, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2%|     | 105M/4.92G [00:29<22:35, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2%|     | 115M/4.92G [00:32<22:30, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏    | 126M/4.92G [00:35<22:55, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏    | 136M/4.92G [00:38<22:42, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏    | 147M/4.92G [00:41<22:35, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏    | 157M/4.92G [00:44<22:53, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏    | 168M/4.92G [00:47<22:38, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏    | 178M/4.92G [00:50<22:31, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏    | 189M/4.92G [00:53<22:17, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏    | 199M/4.92G [00:56<22:40, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏    | 210M/4.92G [00:59<22:25, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏    | 220M/4.92G [01:02<22:14, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5%|▏    | 231M/4.92G [01:05<22:39, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5%|▏    | 241M/4.92G [01:08<22:22, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5%|▎    | 252M/4.92G [01:11<22:10, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5%|▎    | 262M/4.92G [01:14<22:00, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎    | 273M/4.92G [01:17<22:20, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎    | 283M/4.92G [01:20<22:05, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎    | 294M/4.92G [01:23<21:55, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎    | 304M/4.92G [01:26<21:52, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎    | 315M/4.92G [01:29<22:05, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▎    | 325M/4.92G [01:32<21:51, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▎    | 336M/4.92G [01:36<22:12, 3.44MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▎    | 346M/4.92G [01:39<21:58, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▎    | 357M/4.92G [01:42<22:08, 3.43MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▎    | 367M/4.92G [01:45<21:57, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8%|▍    | 377M/4.92G [01:48<21:34, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8%|▍    | 388M/4.92G [01:51<21:32, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8%|▍    | 398M/4.92G [01:53<21:17, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8%|▍    | 409M/4.92G [01:56<21:10, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▍    | 419M/4.92G [02:00<21:32, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▍    | 430M/4.92G [02:02<21:19, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▍    | 440M/4.92G [02:05<21:10, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▍    | 451M/4.92G [02:09<21:29, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▍    | 461M/4.92G [02:11<21:16, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▍    | 472M/4.92G [02:14<21:04, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▍    | 482M/4.92G [02:17<20:56, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▌    | 493M/4.92G [02:21<21:18, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▌    | 503M/4.92G [02:23<21:01, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▌    | 514M/4.92G [02:26<20:51, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11%|▌    | 524M/4.92G [02:29<20:42, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11%|▌    | 535M/4.92G [02:32<21:03, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11%|▌    | 545M/4.92G [02:35<20:49, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11%|▌    | 556M/4.92G [02:38<20:39, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▌    | 566M/4.92G [02:42<20:58, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▌    | 577M/4.92G [02:44<20:43, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▌    | 587M/4.92G [02:47<20:32, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▌    | 598M/4.92G [02:50<20:23, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▌    | 608M/4.92G [02:53<20:43, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▋    | 619M/4.92G [02:56<20:33, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▋    | 629M/4.92G [02:59<20:17, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▋    | 640M/4.92G [03:02<20:09, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▋    | 650M/4.92G [03:05<20:13, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▋    | 661M/4.92G [03:08<20:20, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14%|▋    | 671M/4.92G [03:11<20:12, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14%|▋    | 682M/4.92G [03:14<20:02, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14%|▋    | 692M/4.92G [03:18<20:36, 3.42MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14%|▋    | 703M/4.92G [03:20<20:02, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▋    | 713M/4.92G [03:23<19:53, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▋    | 724M/4.92G [03:26<19:45, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▋    | 734M/4.92G [03:29<20:05, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▊    | 744M/4.92G [03:32<19:52, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▊    | 755M/4.92G [03:35<19:42, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▊    | 765M/4.92G [03:38<20:00, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▊    | 776M/4.92G [03:41<19:45, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▊    | 786M/4.92G [03:44<19:35, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▊    | 797M/4.92G [03:47<19:28, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▊    | 807M/4.92G [03:50<19:20, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▊    | 818M/4.92G [03:53<19:15, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▊    | 828M/4.92G [03:56<19:39, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▊    | 839M/4.92G [03:59<19:25, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▊    | 849M/4.92G [04:02<19:12, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▊    | 860M/4.92G [04:05<19:31, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18%|▉    | 870M/4.92G [04:08<19:16, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18%|▉    | 881M/4.92G [04:11<19:10, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18%|▉    | 891M/4.92G [04:14<19:01, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18%|▉    | 902M/4.92G [04:17<18:54, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|▉    | 912M/4.92G [04:20<19:12, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|▉    | 923M/4.92G [04:23<19:00, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|▉    | 933M/4.92G [04:26<18:50, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|▉    | 944M/4.92G [04:29<19:24, 3.41MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|▉    | 954M/4.92G [04:32<19:05, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|▉    | 965M/4.92G [04:35<18:55, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|▉    | 975M/4.92G [04:38<18:40, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|█    | 986M/4.92G [04:41<18:33, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|█    | 996M/4.92G [04:44<18:26, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|▊   | 1.01G/4.92G [04:47<18:45, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21%|▊   | 1.02G/4.92G [04:50<18:33, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21%|▊   | 1.03G/4.92G [04:53<18:24, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21%|▊   | 1.04G/4.92G [04:56<18:40, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21%|▊   | 1.05G/4.92G [04:59<18:29, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|▊   | 1.06G/4.92G [05:02<18:18, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|▊   | 1.07G/4.92G [05:05<18:10, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|▉   | 1.08G/4.92G [05:08<18:31, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|▉   | 1.09G/4.92G [05:11<18:12, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|▉   | 1.10G/4.92G [05:14<18:06, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|▉   | 1.11G/4.92G [05:17<18:21, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|▉   | 1.12G/4.92G [05:20<18:07, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|▉   | 1.13G/4.92G [05:23<17:57, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|▉   | 1.14G/4.92G [05:26<17:49, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|▉   | 1.15G/4.92G [05:29<18:06, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24%|▉   | 1.16G/4.92G [05:32<17:54, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24%|▉   | 1.17G/4.92G [05:35<17:44, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24%|▉   | 1.18G/4.92G [05:38<17:36, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24%|▉   | 1.20G/4.92G [05:41<17:53, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|▉   | 1.21G/4.92G [05:44<17:46, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|▉   | 1.22G/4.92G [05:47<17:32, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|▉   | 1.23G/4.92G [05:50<17:25, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|█   | 1.24G/4.92G [05:53<17:23, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|█   | 1.25G/4.92G [05:56<17:34, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█   | 1.26G/4.92G [05:59<17:23, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█   | 1.27G/4.92G [06:02<17:14, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█   | 1.28G/4.92G [06:05<17:35, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█   | 1.29G/4.92G [06:08<17:17, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█   | 1.30G/4.92G [06:11<17:09, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27%|█   | 1.31G/4.92G [06:14<17:04, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27%|█   | 1.32G/4.92G [06:17<17:19, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27%|█   | 1.33G/4.92G [06:20<17:06, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27%|█   | 1.34G/4.92G [06:23<16:56, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█   | 1.35G/4.92G [06:26<17:11, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█   | 1.36G/4.92G [06:29<16:58, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█   | 1.37G/4.92G [06:32<16:48, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█▏  | 1.38G/4.92G [06:35<16:44, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█▏  | 1.39G/4.92G [06:38<16:54, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▏  | 1.41G/4.92G [06:41<16:43, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▏  | 1.42G/4.92G [06:44<16:40, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▏  | 1.43G/4.92G [06:47<16:26, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▏  | 1.44G/4.92G [06:50<16:21, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▏  | 1.45G/4.92G [06:53<16:16, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30%|█▏  | 1.46G/4.92G [06:56<16:38, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30%|█▏  | 1.47G/4.92G [06:59<16:22, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30%|█▏  | 1.48G/4.92G [07:02<16:16, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30%|█▏  | 1.49G/4.92G [07:05<16:07, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▏  | 1.50G/4.92G [07:08<16:23, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▏  | 1.51G/4.92G [07:11<16:12, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▏  | 1.52G/4.92G [07:14<16:04, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▏  | 1.53G/4.92G [07:17<16:23, 3.44MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▎  | 1.54G/4.92G [07:20<16:06, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▎  | 1.55G/4.92G [07:23<15:57, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▎  | 1.56G/4.92G [07:26<15:50, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▎  | 1.57G/4.92G [07:29<16:08, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▎  | 1.58G/4.92G [07:32<15:51, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▎  | 1.59G/4.92G [07:35<15:43, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▎  | 1.60G/4.92G [07:38<15:39, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▎  | 1.61G/4.92G [07:41<15:30, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▎  | 1.63G/4.92G [07:44<15:25, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▎  | 1.64G/4.92G [07:47<15:41, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▎  | 1.65G/4.92G [07:50<15:31, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34%|█▎  | 1.66G/4.92G [07:53<15:24, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34%|█▎  | 1.67G/4.92G [07:56<15:18, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34%|█▎  | 1.68G/4.92G [07:59<15:32, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34%|█▎  | 1.69G/4.92G [08:02<15:22, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▍  | 1.70G/4.92G [08:05<15:13, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▍  | 1.71G/4.92G [08:08<15:26, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▍  | 1.72G/4.92G [08:11<15:15, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▍  | 1.73G/4.92G [08:14<15:06, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▍  | 1.74G/4.92G [08:17<14:59, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▍  | 1.75G/4.92G [08:20<15:12, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▍  | 1.76G/4.92G [08:23<15:01, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▍  | 1.77G/4.92G [08:26<14:53, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▍  | 1.78G/4.92G [08:29<15:05, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▍  | 1.79G/4.92G [08:32<14:54, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37%|█▍  | 1.80G/4.92G [08:35<14:45, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37%|█▍  | 1.81G/4.92G [08:38<14:52, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37%|█▍  | 1.82G/4.92G [08:41<14:42, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37%|█▍  | 1.84G/4.92G [08:44<14:34, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▌  | 1.85G/4.92G [08:47<14:50, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▌  | 1.86G/4.92G [08:50<14:34, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▌  | 1.87G/4.92G [08:53<14:26, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▌  | 1.88G/4.92G [08:56<14:20, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▌  | 1.89G/4.92G [08:59<14:36, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▌  | 1.90G/4.92G [09:02<14:21, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▌  | 1.91G/4.92G [09:05<14:14, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▌  | 1.92G/4.92G [09:08<14:07, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▌  | 1.93G/4.92G [09:11<14:20, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▌  | 1.94G/4.92G [09:14<14:13, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40%|█▌  | 1.95G/4.92G [09:17<14:03, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40%|█▌  | 1.96G/4.92G [09:20<13:56, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40%|█▌  | 1.97G/4.92G [09:23<13:51, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40%|█▌  | 1.98G/4.92G [09:26<14:04, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|█▌  | 1.99G/4.92G [09:29<13:54, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|█▋  | 2.00G/4.92G [09:32<13:46, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|█▋  | 2.01G/4.92G [09:35<13:58, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|█▋  | 2.02G/4.92G [09:38<13:48, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|█▋  | 2.03G/4.92G [09:41<13:40, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|█▋  | 2.04G/4.92G [09:44<13:33, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|█▋  | 2.06G/4.92G [09:47<13:45, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|█▋  | 2.07G/4.92G [09:50<13:35, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|█▋  | 2.08G/4.92G [09:53<13:27, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|█▋  | 2.09G/4.92G [09:56<13:38, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43%|█▋  | 2.10G/4.92G [09:59<13:27, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43%|█▋  | 2.11G/4.92G [10:02<13:19, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43%|█▋  | 2.12G/4.92G [10:05<13:12, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43%|█▋  | 2.13G/4.92G [10:08<13:24, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|█▋  | 2.14G/4.92G [10:11<13:14, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|█▋  | 2.15G/4.92G [10:14<13:07, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|█▊  | 2.16G/4.92G [10:17<13:17, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|█▊  | 2.17G/4.92G [10:20<13:08, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|█▊  | 2.18G/4.92G [10:23<12:59, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|█▊  | 2.19G/4.92G [10:26<13:09, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|█▊  | 2.20G/4.92G [10:29<12:58, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|█▊  | 2.21G/4.92G [10:32<12:49, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|█▊  | 2.22G/4.92G [10:35<12:43, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|█▊  | 2.23G/4.92G [10:38<12:54, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|█▊  | 2.24G/4.92G [10:41<12:44, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|█▊  | 2.25G/4.92G [10:44<12:36, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|█▊  | 2.26G/4.92G [10:47<12:46, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|█▊  | 2.28G/4.92G [10:50<12:36, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|█▊  | 2.29G/4.92G [10:53<12:28, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47%|█▊  | 2.30G/4.92G [10:56<12:26, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47%|█▉  | 2.31G/4.92G [10:59<12:17, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47%|█▉  | 2.32G/4.92G [11:02<12:27, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47%|█▉  | 2.33G/4.92G [11:05<12:21, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|█▉  | 2.34G/4.92G [11:08<12:11, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|█▉  | 2.35G/4.92G [11:11<12:05, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|█▉  | 2.36G/4.92G [11:14<12:00, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|█▉  | 2.37G/4.92G [11:17<12:16, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|█▉  | 2.38G/4.92G [11:20<12:03, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|█▉  | 2.39G/4.92G [11:23<11:56, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|█▉  | 2.40G/4.92G [11:26<11:50, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|█▉  | 2.41G/4.92G [11:29<12:01, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|█▉  | 2.42G/4.92G [11:32<11:52, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|█▉  | 2.43G/4.92G [11:35<11:45, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50%|█▉  | 2.44G/4.92G [11:38<11:54, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50%|█▉  | 2.45G/4.92G [11:41<11:44, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50%|██  | 2.46G/4.92G [11:44<11:37, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50%|██  | 2.47G/4.92G [11:47<11:31, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██  | 2.49G/4.92G [11:50<11:40, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██  | 2.50G/4.92G [11:53<11:31, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██  | 2.51G/4.92G [11:56<11:25, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██  | 2.52G/4.92G [11:59<11:33, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██  | 2.53G/4.92G [12:02<11:24, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██  | 2.54G/4.92G [12:05<11:16, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██  | 2.55G/4.92G [12:08<11:10, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██  | 2.56G/4.92G [12:11<11:05, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██  | 2.57G/4.92G [12:14<11:15, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██  | 2.58G/4.92G [12:17<11:07, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53%|██  | 2.59G/4.92G [12:20<11:00, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53%|██  | 2.60G/4.92G [12:23<11:10, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53%|██  | 2.61G/4.92G [12:26<11:00, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53%|██▏ | 2.62G/4.92G [12:29<10:53, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▏ | 2.63G/4.92G [12:32<11:00, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▏ | 2.64G/4.92G [12:35<10:51, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▏ | 2.65G/4.92G [12:38<10:44, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▏ | 2.66G/4.92G [12:41<10:38, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▏ | 2.67G/4.92G [12:44<10:46, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▏ | 2.68G/4.92G [12:47<10:39, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▏ | 2.69G/4.92G [12:50<10:33, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▏ | 2.71G/4.92G [12:53<10:27, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▏ | 2.72G/4.92G [12:55<10:20, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▏ | 2.73G/4.92G [12:59<10:29, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56%|██▏ | 2.74G/4.92G [13:02<10:21, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56%|██▏ | 2.75G/4.92G [13:04<10:15, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56%|██▏ | 2.76G/4.92G [13:07<10:10, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56%|██▎ | 2.77G/4.92G [13:11<10:18, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.78G/4.92G [13:14<10:10, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.79G/4.92G [13:16<10:04, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.80G/4.92G [13:19<09:59, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.81G/4.92G [13:22<09:55, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.82G/4.92G [13:26<10:03, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.83G/4.92G [13:28<09:55, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.84G/4.92G [13:31<09:49, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.85G/4.92G [13:35<09:56, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.86G/4.92G [13:37<09:47, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.87G/4.92G [13:40<09:41, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59%|██▎ | 2.88G/4.92G [13:43<09:35, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59%|██▎ | 2.89G/4.92G [13:47<09:43, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59%|██▎ | 2.90G/4.92G [13:49<09:35, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59%|██▎ | 2.92G/4.92G [13:52<09:28, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▍ | 2.93G/4.92G [13:55<09:23, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▍ | 2.94G/4.92G [13:58<09:31, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▍ | 2.95G/4.92G [14:01<09:23, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▍ | 2.96G/4.92G [14:04<09:16, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▍ | 2.97G/4.92G [14:08<09:23, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|██▍ | 2.98G/4.92G [14:10<09:17, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|██▍ | 2.99G/4.92G [14:13<09:10, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|██▍ | 3.00G/4.92G [14:16<09:02, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|██▍ | 3.01G/4.92G [14:19<09:09, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|██▍ | 3.02G/4.92G [14:22<09:02, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|██▍ | 3.03G/4.92G [14:25<08:56, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|██▍ | 3.04G/4.92G [14:28<08:51, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|██▍ | 3.05G/4.92G [14:31<08:57, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|██▍ | 3.06G/4.92G [14:34<08:50, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|██▍ | 3.07G/4.92G [14:37<08:43, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63%|██▌ | 3.08G/4.92G [14:40<08:49, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63%|██▌ | 3.09G/4.92G [14:43<08:42, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63%|██▌ | 3.10G/4.92G [14:46<08:35, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63%|██▌ | 3.11G/4.92G [14:50<08:41, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|██▌ | 3.12G/4.92G [14:52<08:33, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|██▌ | 3.14G/4.92G [14:55<08:28, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|██▌ | 3.15G/4.92G [14:58<08:22, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|██▌ | 3.16G/4.92G [15:01<08:17, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|██▌ | 3.17G/4.92G [15:04<08:25, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|██▌ | 3.18G/4.92G [15:07<08:16, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|██▌ | 3.19G/4.92G [15:10<08:10, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|██▌ | 3.20G/4.92G [15:13<08:16, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|██▌ | 3.21G/4.92G [15:16<08:08, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|██▌ | 3.22G/4.92G [15:19<08:02, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66%|██▋ | 3.23G/4.92G [15:22<07:57, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66%|██▋ | 3.24G/4.92G [15:25<08:04, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66%|██▋ | 3.25G/4.92G [15:28<07:56, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66%|██▋ | 3.26G/4.92G [15:31<07:50, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|██▋ | 3.27G/4.92G [15:35<07:56, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|██▋ | 3.28G/4.92G [15:37<07:48, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|██▋ | 3.29G/4.92G [15:40<07:42, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|██▋ | 3.30G/4.92G [15:43<07:37, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|██▋ | 3.31G/4.92G [15:46<07:42, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|██▋ | 3.32G/4.92G [15:49<07:35, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|██▋ | 3.33G/4.92G [15:52<07:30, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|██▋ | 3.34G/4.92G [15:56<07:33, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|██▋ | 3.36G/4.92G [15:58<07:28, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|██▋ | 3.37G/4.92G [16:01<07:20, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|██▋ | 3.38G/4.92G [16:04<07:15, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|██▊ | 3.39G/4.92G [16:07<07:20, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|██▊ | 3.40G/4.92G [16:10<07:14, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|██▊ | 3.41G/4.92G [16:13<07:08, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|██▊ | 3.42G/4.92G [16:16<07:03, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|██▊ | 3.43G/4.92G [16:19<07:08, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|██▊ | 3.44G/4.92G [16:22<07:02, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|██▊ | 3.45G/4.92G [16:25<06:57, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|██▊ | 3.46G/4.92G [16:28<07:01, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|██▊ | 3.47G/4.92G [16:31<06:54, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|██▊ | 3.48G/4.92G [16:34<06:48, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|██▊ | 3.49G/4.92G [16:37<06:43, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|██▊ | 3.50G/4.92G [16:40<06:48, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|██▊ | 3.51G/4.92G [16:43<06:41, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72%|██▊ | 3.52G/4.92G [16:46<06:36, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72%|██▉ | 3.53G/4.92G [16:49<06:39, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72%|██▉ | 3.54G/4.92G [16:52<06:32, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72%|██▉ | 3.55G/4.92G [16:55<06:27, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|██▉ | 3.57G/4.92G [16:58<06:23, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|██▉ | 3.58G/4.92G [17:01<06:18, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|██▉ | 3.59G/4.92G [17:04<06:14, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|██▉ | 3.60G/4.92G [17:07<06:19, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|██▉ | 3.61G/4.92G [17:10<06:13, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|██▉ | 3.62G/4.92G [17:13<06:08, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|██▉ | 3.63G/4.92G [17:16<06:12, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|██▉ | 3.64G/4.92G [17:19<06:05, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|██▉ | 3.65G/4.92G [17:22<06:00, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|██▉ | 3.66G/4.92G [17:25<05:55, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75%|██▉ | 3.67G/4.92G [17:28<05:52, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75%|██▉ | 3.68G/4.92G [17:31<05:48, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75%|███ | 3.69G/4.92G [17:34<05:54, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75%|███ | 3.70G/4.92G [17:37<05:54, 3.43MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███ | 3.71G/4.92G [17:40<05:47, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███ | 3.72G/4.92G [17:43<05:41, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███ | 3.73G/4.92G [17:46<05:43, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███ | 3.74G/4.92G [17:49<05:36, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███ | 3.75G/4.92G [17:52<05:31, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███ | 3.76G/4.92G [17:55<05:33, 3.45MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███ | 3.77G/4.92G [17:58<05:27, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███ | 3.79G/4.92G [18:01<05:22, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███ | 3.80G/4.92G [18:04<05:18, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███ | 3.81G/4.92G [18:07<05:13, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███ | 3.82G/4.92G [18:10<05:09, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███ | 3.83G/4.92G [18:13<05:13, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███ | 3.84G/4.92G [18:16<05:07, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███▏| 3.85G/4.92G [18:19<05:03, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███▏| 3.86G/4.92G [18:22<05:05, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79%|███▏| 3.87G/4.92G [18:25<04:59, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79%|███▏| 3.88G/4.92G [18:28<04:55, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79%|███▏| 3.89G/4.92G [18:31<04:50, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79%|███▏| 3.90G/4.92G [18:34<04:53, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▏| 3.91G/4.92G [18:37<04:47, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▏| 3.92G/4.92G [18:40<04:42, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▏| 3.93G/4.92G [18:43<04:38, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▏| 3.94G/4.92G [18:46<04:40, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▏| 3.95G/4.92G [18:49<04:35, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|███▏| 3.96G/4.92G [18:52<04:30, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|███▏| 3.97G/4.92G [18:55<04:32, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|███▏| 3.98G/4.92G [18:58<04:26, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|███▎| 4.00G/4.92G [19:01<04:22, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|███▎| 4.01G/4.92G [19:04<04:23, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82%|███▎| 4.02G/4.92G [19:07<04:17, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82%|███▎| 4.03G/4.92G [19:10<04:13, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82%|███▎| 4.04G/4.92G [19:13<04:09, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82%|███▎| 4.05G/4.92G [19:16<04:05, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|███▎| 4.06G/4.92G [19:19<04:06, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|███▎| 4.07G/4.92G [19:22<04:02, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|███▎| 4.08G/4.92G [19:25<03:57, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|███▎| 4.09G/4.92G [19:28<03:54, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|███▎| 4.10G/4.92G [19:31<03:55, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|███▎| 4.11G/4.92G [19:34<03:50, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|███▎| 4.12G/4.92G [19:37<03:46, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|███▎| 4.13G/4.92G [19:40<03:46, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|███▎| 4.14G/4.92G [19:43<03:41, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|███▍| 4.15G/4.92G [19:46<03:37, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85%|███▍| 4.16G/4.92G [19:49<03:33, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85%|███▍| 4.17G/4.92G [19:52<03:34, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85%|███▍| 4.18G/4.92G [19:55<03:29, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85%|███▍| 4.19G/4.92G [19:58<03:25, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|███▍| 4.20G/4.92G [20:01<03:25, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|███▍| 4.22G/4.92G [20:04<03:20, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|███▍| 4.23G/4.92G [20:07<03:16, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|███▍| 4.24G/4.92G [20:10<03:12, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|███▍| 4.25G/4.92G [20:13<03:13, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|███▍| 4.26G/4.92G [20:16<03:08, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|███▍| 4.27G/4.92G [20:19<03:04, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|███▍| 4.28G/4.92G [20:22<03:04, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|███▍| 4.29G/4.92G [20:25<03:00, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|███▍| 4.30G/4.92G [20:28<02:55, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88%|███▌| 4.31G/4.92G [20:31<02:54, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88%|███▌| 4.32G/4.92G [20:34<02:52, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88%|███▌| 4.33G/4.92G [20:37<02:47, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88%|███▌| 4.34G/4.92G [20:40<02:43, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|███▌| 4.35G/4.92G [20:43<02:39, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|███▌| 4.36G/4.92G [20:46<02:39, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|███▌| 4.37G/4.92G [20:49<02:35, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|███▌| 4.38G/4.92G [20:52<02:31, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|███▌| 4.39G/4.92G [20:55<02:31, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|███▌| 4.40G/4.92G [20:58<02:26, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|███▌| 4.41G/4.92G [21:01<02:22, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|███▌| 4.42G/4.92G [21:04<02:19, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|███▌| 4.44G/4.92G [21:07<02:18, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|███▌| 4.45G/4.92G [21:10<02:14, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91%|███▋| 4.46G/4.92G [21:13<02:10, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91%|███▋| 4.47G/4.92G [21:16<02:09, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91%|███▋| 4.48G/4.92G [21:19<02:05, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91%|███▋| 4.49G/4.92G [21:22<02:01, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|███▋| 4.50G/4.92G [21:25<01:58, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|███▋| 4.51G/4.92G [21:28<01:57, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|███▋| 4.52G/4.92G [21:31<01:53, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|███▋| 4.53G/4.92G [21:34<01:50, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|███▋| 4.54G/4.92G [21:37<01:46, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|███▋| 4.55G/4.92G [21:40<01:43, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|███▋| 4.56G/4.92G [21:43<01:39, 3.55MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|███▋| 4.57G/4.92G [21:46<01:38, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|███▋| 4.58G/4.92G [21:49<01:35, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|███▋| 4.59G/4.92G [21:52<01:31, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|███▋| 4.60G/4.92G [21:55<01:28, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|███▊| 4.61G/4.92G [21:58<01:25, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|███▊| 4.62G/4.92G [22:01<01:23, 3.48MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|███▊| 4.63G/4.92G [22:04<01:20, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|███▊| 4.65G/4.92G [22:07<01:16, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95%|███▊| 4.66G/4.92G [22:10<01:13, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95%|███▊| 4.67G/4.92G [22:13<01:11, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95%|███▊| 4.68G/4.92G [22:16<01:08, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95%|███▊| 4.69G/4.92G [22:19<01:04, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|███▊| 4.70G/4.92G [22:22<01:03, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|███▊| 4.71G/4.92G [22:25<00:59, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|███▊| 4.72G/4.92G [22:28<00:56, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|███▊| 4.73G/4.92G [22:31<00:53, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|███▊| 4.74G/4.92G [22:34<00:50, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|███▊| 4.75G/4.92G [22:37<00:47, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|███▊| 4.76G/4.92G [22:40<00:44, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|███▉| 4.77G/4.92G [22:43<00:40, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|███▉| 4.78G/4.92G [22:46<00:38, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|███▉| 4.79G/4.92G [22:49<00:35, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98%|███▉| 4.80G/4.92G [22:52<00:32, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98%|███▉| 4.81G/4.92G [22:55<00:29, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98%|███▉| 4.82G/4.92G [22:58<00:26, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98%|███▉| 4.83G/4.92G [23:01<00:23, 3.49MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|███▉| 4.84G/4.92G [23:04<00:20, 3.51MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|███▉| 4.85G/4.92G [23:07<00:17, 3.53MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|███▉| 4.87G/4.92G [23:10<00:14, 3.54MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|███▉| 4.88G/4.92G [23:13<00:11, 3.47MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|███▉| 4.89G/4.92G [23:16<00:08, 3.50MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100%|███▉| 4.90G/4.92G [23:19<00:05, 3.52MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100%|███▉| 4.91G/4.92G [23:22<00:02, 3.46MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100%|████| 4.92G/4.92G [23:24<00:00, 3.50MB/s]\u001b[A\n",
            "Downloading shards:  75%|███████████████▊     | 3/4 [1:11:05<23:38, 1418.87s/it]\n",
            "model-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   1%|    | 10.5M/1.17G [00:02<05:23, 3.57MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   2%|    | 21.0M/1.17G [00:05<05:21, 3.57MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3%|    | 31.5M/1.17G [00:09<05:30, 3.44MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   4%|▏   | 41.9M/1.17G [00:11<05:22, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   4%|▏   | 52.4M/1.17G [00:14<05:19, 3.50MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   5%|▏   | 62.9M/1.17G [00:17<05:12, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   6%|▎   | 73.4M/1.17G [00:20<05:08, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   7%|▎   | 83.9M/1.17G [00:23<05:11, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   8%|▎   | 94.4M/1.17G [00:26<05:06, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   9%|▍    | 105M/1.17G [00:29<05:01, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  10%|▍    | 115M/1.17G [00:32<05:04, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  11%|▌    | 126M/1.17G [00:35<04:58, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  12%|▌    | 136M/1.17G [00:38<04:53, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13%|▋    | 147M/1.17G [00:42<04:55, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13%|▋    | 157M/1.17G [00:44<04:49, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  14%|▋    | 168M/1.17G [00:47<04:44, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  15%|▊    | 178M/1.17G [00:50<04:40, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  16%|▊    | 189M/1.17G [00:53<04:42, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17%|▊    | 199M/1.17G [00:56<04:38, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  18%|▉    | 210M/1.17G [00:59<04:32, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  19%|▉    | 220M/1.17G [01:02<04:28, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  20%|▉    | 231M/1.17G [01:05<04:24, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21%|█    | 241M/1.17G [01:09<04:29, 3.44MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  22%|█    | 252M/1.17G [01:11<04:23, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  22%|█    | 262M/1.17G [01:15<04:22, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  23%|█▏   | 273M/1.17G [01:17<04:16, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24%|█▏   | 283M/1.17G [01:20<04:12, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  25%|█▎   | 294M/1.17G [01:24<04:13, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  26%|█▎   | 304M/1.17G [01:27<04:07, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  27%|█▎   | 315M/1.17G [01:29<04:04, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  28%|█▍   | 325M/1.17G [01:32<03:58, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  29%|█▍   | 336M/1.17G [01:35<03:56, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  30%|█▍   | 346M/1.17G [01:38<03:51, 3.56MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31%|█▌   | 357M/1.17G [01:41<03:52, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31%|█▌   | 367M/1.17G [01:44<03:48, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  32%|█▌   | 377M/1.17G [01:47<03:44, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  33%|█▋   | 388M/1.17G [01:50<03:40, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  34%|█▋   | 398M/1.17G [01:54<03:45, 3.41MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35%|█▊   | 409M/1.17G [01:56<03:39, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  36%|█▊   | 419M/1.17G [02:00<03:38, 3.42MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  37%|█▊   | 430M/1.17G [02:03<03:33, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  38%|█▉   | 440M/1.17G [02:06<03:28, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  39%|█▉   | 451M/1.17G [02:08<03:24, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  39%|█▉   | 461M/1.17G [02:12<03:24, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  40%|██   | 472M/1.17G [02:15<03:19, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  41%|██   | 482M/1.17G [02:18<03:15, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  42%|██   | 493M/1.17G [02:21<03:15, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  43%|██▏  | 503M/1.17G [02:24<03:10, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  44%|██▏  | 514M/1.17G [02:27<03:06, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  45%|██▏  | 524M/1.17G [02:30<03:06, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46%|██▎  | 535M/1.17G [02:33<03:01, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  47%|██▎  | 545M/1.17G [02:36<02:57, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  48%|██▍  | 556M/1.17G [02:39<02:53, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  48%|██▍  | 566M/1.17G [02:42<02:53, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  49%|██▍  | 577M/1.17G [02:45<02:49, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  50%|██▌  | 587M/1.17G [02:48<02:45, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  51%|██▌  | 598M/1.17G [02:51<02:42, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  52%|██▌  | 608M/1.17G [02:53<02:37, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  53%|██▋  | 619M/1.17G [02:56<02:34, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  54%|██▋  | 629M/1.17G [02:59<02:31, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  55%|██▋  | 640M/1.17G [03:02<02:31, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  56%|██▊  | 650M/1.17G [03:05<02:27, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57%|██▊  | 661M/1.17G [03:08<02:23, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57%|██▊  | 671M/1.17G [03:11<02:21, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  58%|██▉  | 682M/1.17G [03:14<02:17, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  59%|██▉  | 692M/1.17G [03:17<02:14, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  60%|███  | 703M/1.17G [03:20<02:11, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  61%|███  | 713M/1.17G [03:23<02:10, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  62%|███  | 724M/1.17G [03:26<02:06, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  63%|███▏ | 734M/1.17G [03:29<02:03, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  64%|███▏ | 744M/1.17G [03:32<01:59, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  65%|███▏ | 755M/1.17G [03:35<01:56, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66%|███▎ | 765M/1.17G [03:38<01:53, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  66%|███▎ | 776M/1.17G [03:41<01:53, 3.45MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  67%|███▎ | 786M/1.17G [03:44<01:50, 3.44MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  68%|███▍ | 797M/1.17G [03:47<01:46, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  69%|███▍ | 807M/1.17G [03:50<01:44, 3.44MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70%|███▌ | 818M/1.17G [03:53<01:40, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  71%|███▌ | 828M/1.17G [03:56<01:36, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  72%|███▌ | 839M/1.17G [03:59<01:33, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  73%|███▋ | 849M/1.17G [04:02<01:30, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  74%|███▋ | 860M/1.17G [04:05<01:28, 3.47MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75%|███▋ | 870M/1.17G [04:08<01:25, 3.50MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75%|███▊ | 881M/1.17G [04:11<01:21, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  76%|███▊ | 891M/1.17G [04:14<01:18, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  77%|███▊ | 902M/1.17G [04:17<01:16, 3.46MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78%|███▉ | 912M/1.17G [04:20<01:13, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  79%|███▉ | 923M/1.17G [04:23<01:09, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  80%|███▉ | 933M/1.17G [04:26<01:06, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  81%|████ | 944M/1.17G [04:29<01:03, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82%|████ | 954M/1.17G [04:32<01:00, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83%|████▏| 965M/1.17G [04:35<00:57, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  83%|████▏| 975M/1.17G [04:38<00:55, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  84%|████▏| 986M/1.17G [04:41<00:52, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  85%|████▎| 996M/1.17G [04:44<00:48, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  86%|███▍| 1.01G/1.17G [04:47<00:45, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  87%|███▍| 1.02G/1.17G [04:50<00:42, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  88%|███▌| 1.03G/1.17G [04:53<00:39, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  89%|███▌| 1.04G/1.17G [04:56<00:37, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  90%|███▌| 1.05G/1.17G [04:59<00:34, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  91%|███▋| 1.06G/1.17G [05:02<00:31, 3.51MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92%|███▋| 1.07G/1.17G [05:05<00:27, 3.55MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92%|███▋| 1.08G/1.17G [05:08<00:25, 3.48MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  93%|███▋| 1.09G/1.17G [05:11<00:22, 3.49MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  94%|███▊| 1.10G/1.17G [05:14<00:19, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95%|███▊| 1.11G/1.17G [05:17<00:16, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  96%|███▊| 1.12G/1.17G [05:20<00:13, 3.47MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  97%|███▉| 1.13G/1.17G [05:23<00:10, 3.50MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  98%|███▉| 1.14G/1.17G [05:26<00:07, 3.52MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  99%|███▉| 1.15G/1.17G [05:29<00:04, 3.53MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100%|███▉| 1.16G/1.17G [05:32<00:01, 3.54MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100%|████| 1.17G/1.17G [05:33<00:00, 3.51MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████| 4/4 [1:16:39<00:00, 1149.76s/it]\n",
            "[INFO|modeling_utils.py:1519] 2024-06-24 16:09:13,824 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 16:09:13,825 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:00<00:00, 10.74it/s]\n",
            "[INFO|modeling_utils.py:4280] 2024-06-24 16:09:14,232 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4288] 2024-06-24 16:09:14,233 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "generation_config.json: 100%|███████████████████| 131/131 [00:00<00:00, 553kB/s]\n",
            "[INFO|configuration_utils.py:917] 2024-06-24 16:09:14,933 >> loading configuration file generation_config.json from cache at /home/anonymous/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/generation_config.json\n",
            "[INFO|configuration_utils.py:962] 2024-06-24 16:09:14,934 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128009\n",
            "  ]\n",
            "}\n",
            "\n",
            "06/24/2024 16:09:14 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "06/24/2024 16:10:14 - INFO - llamafactory.model.adapter - Merged 1 adapter(s).\n",
            "06/24/2024 16:10:14 - INFO - llamafactory.model.adapter - Loaded adapter(s): llama3_lora\n",
            "06/24/2024 16:10:14 - INFO - llamafactory.model.loader - all params: 8030261248\n",
            "[INFO|configuration_utils.py:472] 2024-06-24 16:10:14,192 >> Configuration saved in llama3_lora_merged/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-06-24 16:10:14,192 >> Configuration saved in llama3_lora_merged/generation_config.json\n",
            "[INFO|modeling_utils.py:2626] 2024-06-24 16:10:25,666 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 9 checkpoint shards. You can find where each parameters has been saved in the index located at llama3_lora_merged/model.safetensors.index.json.\n",
            "[INFO|tokenization_utils_base.py:2513] 2024-06-24 16:10:25,681 >> tokenizer config file saved in llama3_lora_merged/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2522] 2024-06-24 16:10:25,682 >> Special tokens file saved in llama3_lora_merged/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  model_name_or_path=\"unsloth/llama-3-8b-Instruct\", # use official non-quantized Llama-3-8B-Instruct model\n",
        "  adapter_name_or_path=\"llama3_lora\",            # load the saved LoRA adapters\n",
        "  template=\"llama3\",                     # same to the one in training\n",
        "  finetuning_type=\"lora\",                  # same to the one in training\n",
        "  export_dir=\"llama3_lora_merged\",              # the path to save the merged model\n",
        "  export_size=2,                       # the file shard size (in GB) of the merged model\n",
        "  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n",
        "  #export_hub_model_id=\"your_id/your_model\",         # the Hugging Face hub ID to upload model\n",
        ")\n",
        "\n",
        "json.dump(args, open(\"merge_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "# %cd /content/LLaMA-Factory/\n",
        "\n",
        "!llamafactory-cli export merge_llama3.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
